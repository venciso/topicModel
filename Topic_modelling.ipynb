{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling \n",
    "\n",
    "In this notebook I will explore topic modeling for the 20newsgroups dataset. \n",
    "The notebook flow is as follows:\n",
    "* Import the dataset and initial preprocessing/cleaning\n",
    "* Use the spacy package to tokenize, lemmatize and create a tri-gram model for the documents\n",
    "* Perform topic modeling using Latent Dirichlet Allocation (LDA) and Non-negative Matrix Factorization (NMF)\n",
    "* Measure the 'goodness' of the LDA and NMF models. \n",
    "* Apply the the resulting model to unseen documents to derive its topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some spacy installation notes: \n",
    "* In order to install spacy visual studio build tools is needed http://landinghub.visualstudio.com/visual-cpp-build-tools\n",
    "* To download the spacy english model in python 3 execute this command as admin: python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary packages and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venciso\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py36\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import os\n",
    "import pickle \n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from numpy import exp\n",
    "import string\n",
    "import numpy as np\n",
    "from math import sqrt,isnan\n",
    "from gensim.models import Phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the documents and perform some initial cleaning, i.e., there are newline and tab characters spread across the documents which become a problem later on if not removed.\n",
    "Make everything lower-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "dataset.data = [d.replace('\\n', ' ') for d in dataset.data]\n",
    "dataset.data = [d.replace('\\t', ' ') for d in dataset.data]\n",
    "dataset.data = [d.replace(\"'\",\"\") for d in dataset.data]\n",
    "dataset.data = [d.lower() for d in dataset.data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of documents in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some initial modeling of the data it became clear that there were a few documents that were just gibberish and were affecting the results. \n",
    "\n",
    "Onse such example can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  ------------ part 11 of 14 ------------ mr1865%22dm75u=75u4)\"0iv=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=0m75u=625!;)b8e,3`]g9s2+[>wm4qd]f0->7exjwz5f,8>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax<q9j5znp.9f3v9f9f9f3w2tg%q&1fpl%-3[>wm[>wm[5-3l+!3l+`9 m&1d9&7%q<7%q<7%q&72tct]/=+2tm+2tm+2/3t]/3t]/=+2tg%qtcv9f0,# m`p->7ez[n[lj>gizw]]1z6ei0l+9f9f9f9f9f;$q,3$q,3$q,3$9f8+\"pl+ mi:5>ghj*bhjn[m>7ey>7@.9/3w2tg%q<1d9l%-3[8n+-,5g9p],3$q,3$q, m3$r)b8f)b8g)r<g)r<g)r<g)r186r<g)r<g)r<g)r<g)r<f)b8f)b8f)b8f) mb8g)r<g)r<g)r<f)b8e,3$q,3$q,3$q,3(f)b8f)b8f)b8f)b4q,3&?%-(om m[5-34u.p&72/3v9f0,#`uy>7@,#`yf9f3t]/3t]f9d]f9f9f3t]/3w2tm+2 m<7$9&1fpl+!3l!d9&1d9&7%q&1d9l+`9&;\"p&1d9<=(]/9f9f9d#`uz[nriz mw]_?w]_?w]_?>giz>giz*bhj>giz>bhj>giz>giz>gk?1t=1t=1t=1t>e m\"v;$,8>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax?$9@mwwhj m7@.9tafp[31g3$r)b<g)%e14di+5u=75u4)\"0iv=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=0m75u9)45!;)b8f)3$qgq<4tb^vpl!d9&1d9 m&72/0.[wz7$ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax<qq`mwwhj*kn[n[n[7ey>7ey>`yd] mtg%q&1d9&1eq<=+2tm+2tct]/3t]f9f9f3t]tm+2tm(]/3t]/9d]/3w2tm(] m/3v9f9f9f9f9f3v9f0->7ey>7ey>n[n[*bhj>giz>m]1t>e\"v9fq,3$q,3$ m,3$q,<3$q,3$q,1f9@l+i:6e1t??>ghj*bhj*kn[7ey>`yf9/3w2tg%q&1fp m4u/m[8lt-,5g#tq,3$q,3$q,3(f)b8g)r<g)r<g)r<g)r<d6%a86%a86%a86 mr<g)r<g)r<f)b8f)b8f)b8f)b8f)b<g)r<g)r8f)b8f)b8f)b8f)b8f)b8f) mb8f)b8f)b4p/9s2+[>wm[5.p&72tm(]/3v9f9d]/=+2/=+2<72tm+2tm(] m/=+2tm+2tm+2tm+2tm)q<1d9l+\"p&1eq<7%q<72tg%q<=+2<7%q<1d9<72 mtm+2tcv9`uy>nriz>giz>gizw]_?w]_?>gk?>giz>giz>giz>giz>m_?w]] m1t>ei4=1t=1t>e\"v8qax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax<qq`ne1]\\\\jnux#f3w2&;#m-&=,3(f)r<d6%e22dm75u=75u4)\"0iv= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g4+5u=75de14%a;)b8e, m#v?%q<7%9\\\\7%-(n+bxn+bu,9<=(]`uxjwz4+9l0qax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> m,<1f\"pne1t=1t??wwhjnux#f3w2tm+2tm+2/9d#`p,#`p,#`uz[n[m>7@.9 mf9d]f9f9`p,#`p.9f9d]/3t]/3w2tm+2/9f9`p->7ez[nrhj*bhj*bhj*biz m>gizwt=i0mfq,0qax>ax<q,3$q,<3$q,3$q&9f\"pl+\"pne1]_?>bhj*bj[ mnuy>7ey>`p.9f3w2tg%q&;\"p4u/mbxltq6</3$q,3(f)3$r)b8f)b<g)r<g) mr<g)r186%a86%a86%a86%a86%a;)r<g)r<g)b8f)b8f)b8f)r<g)b8g)r<g) mr<f)b8g)r<g)b8f)b8f)b8f)b8e,#\\\\4t-(om4u.p&7%q<1d9<=+2tg%q&1fp ml+\"pl+`9&7%qtm)q<7%q<72tm+2/3t]f3w2tg%q<7%q<=+2tm(]/3t]/=+2 m<=)q<7%q<1d9&7$9<72tcv9f9f9`uz[*bhj*biz>gk?w]_?>giz*biz>giz m>gk?wt=1t=1t=1t>ei:6ei0l+\"pmfq,0qax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>as$q&8+i=]z*km>`yd]<1fp[33%9tq,3(f)r<d6 m5%22di+5u=75u=5\"0d)\"g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9u\"0d+5 mu=75di*25!;)r8f)3$q,3`\\\\/3$r)b8e,3$p/9p],3&?%-(om4[`9&72`uxj mwt<+9c&ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>as$q,<1f9@ne1]_?wwhjnux#f0,#`p-> m7ey>7klj*bhj>gk?wwhj*km>`p.9f0,#`uy>7@,#`p,#`yf9f9d]tm+2/9f9 m`uy>n[n[*giz>gk?wwizw]]i:4+\"pmfq,0q,8>ax>ax<q,<3$q&9f9f9f m9f9f9f9f9@ne1]_?>ghj*kn[nuy>7ex#`p.9f3w2tg$9l+!34^v+bs3%9v</ m3$q,3(f)b8f)b8f)r<g)r<g)r186%a86%a86%a86%a86%a86%a;)r<g)r<g) mr<f)b8f)r<g)r<g)r<g)r<g)r<g)r8f)b<g)r8f)b4q,#v?%-(om4[\"pl+\"p ml+`9&1d9&1fp4^wm[8n+b^u3l+\"pl+\"pl+\"pl!d9<=+2/9f9f9d]/=+2tm+2 mtct]/3t]tg%q<7$9&1d9&1d9&1d9l+\"p&7%qtct]/3t]f9f9`uz[nrhj*bhj m*bhj>giz>gk?w]_?w]]i0l+\"pl+\"pl+i4=1z4+\"v9fq,0q,8>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax<q,<1f\"t??>bj[7@.9/=)q m&;!3[8lt-,5g#tq,b8g)%a945%22di+5u=75u=5\"0d)\"g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9u\"0m75u=75u9*25%06%lg)r8e,3$p/#p],3$r)b8f)b8f)r<f) mb8f)3$q,#v?%b^u3l+`9tid#nwk?1pmfq#&ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> mas$q,1f9@l+\"z6e1t??1t??wt>ei0l+\"pmf\"z51t??wwhj*kn[n[n[7ey> m7ey>7ey>7@,#f3t]tm(]/9f9`p->7klj*biz>m_?wt>ei:6e\"pl+\"v;$,3& max>ax>as$qq,3$q&9f9f9f9f9f9f8+\"pne1t??wrhjn[n[7ey>7ey>`p.9 mf3w2<1fp4u/m[>wmbxltq6</3$q,3(f)b8f)r<g)r<g)r<g)%a86%a86%a86 m%a86%a86%a86%a;)r<g)r<g)r<g)r<g)r<g)r<g)r<g)r<f)r<g)b8f)b4q, m3&<tb^u3l+\"pl%/m[>u34u/m[8n+-#0t-#0t-#0t-(lt-(n+[>wm[>u3l!eq m/3t]/3t]/=+2/=+2tct]/3t]tg$9&1d9&1d9&1d9&1d9&1d9&1eqtm+2tm+2 mtm(]/9d#7ey>7ez[nrhj>gk?w]_?1t>ei0mf9l3$9l3$q#$9f8+\"po$q#& max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>,<1f m\"pne1whj*km>7@.9/=)q&;!3[8ltq6</3$r)b8g)r186%e145%22di*2u=75 mu=75u4)\"0iv=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9u\"0d+5u=75u=75di*25%06%lg)r<f)b8f) mb8f)b<f)b<g)r<d6%a86%a;)r<g)r8f)3$q,3`]gq32+[;`9tcv9`uz[>m] m\"\\\\2ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>,<3$q#$qax>ax>ax>ax> max>ax<q9@ne1t??wwhj*bhj*bj[*bj[nux#f3w2tm+2tct]f9d#7kn[*bhj m>m_?1t>ei0l+9f;$q,0q,8>ax>ax>as$q,3$qq,3$q,3$q&9f9f8+\"pne mi4=wwiz*bj[nuy>7ey>`yf9/=)q&1fp4^wm[8n+bs3%9v=,3$q,b8f)b<g) mr<g)r<g)r<g)%a86%a86%a86%a86%a86%a86%a86r<g)r<g)r<g)r<g)b8g) mr<g)r8f)b8f)3$q,#v<tb^wm4u-3[8n+bxlt-#0t-#3%q6=gq<7%9v=g#p]g m9v=gq32+b^wm[5.p&1d9&1d9<=+2/=)q<=+2<7%q&1d9&1d9&1d9&1d9&1d9 m&1eqtm+2/3t]/=)q<7%qtm(]/9d#7klj>gizw]_?wt=i0mf9l0q,3&ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>,<1f9@ne1]]z>bj[nuy>`yd]tg$9l%/mbxlt-,5g#tq,3$r) mb8f)r<d6%e145)*2u=75u=75u=75u=5\"0d)\"0d*=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9u\"0d)\"0d+5u=75 mu=62de14%a;)r8f)b8f)b8f)r<g)r<g)r<g)r<g)r<g)r<g)r<f)b4q,3$q, m#p\\\\/9v?%q30t-(oml!g2/0,j1plqax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax<q9@ne1t=1t=w]]z*bhjnuy> m`p.9f3t]f9d#`uz[nrhj*bhj>gk?wt>ei0mf9f;$,3$qax>ax>ax>ax<q m,3$q,3$q,3$qq&9f9f9f9@l+i:6e1t??>ghjn[n[7ey>`yd]/=)q&1fp4u/m m[8n+-,5g#tq,3$q,b8f)r<g)r<g)r<g)r186%a86%a86%a86%a86%a86%a86 m%a86%lg)r<g)r<g)r<g)r<g)b8f)3$p/9\\\\4tbxn+bs0t-,5g9p\\\\/3$q,#p\\\\/ m#p],#p\\\\/#p\\\\/#tq,3$q,#p]gq30tbxn+[>u34[\"p&1d9&7%qtg$9&;\"pl+\"p m&1d9<1eq<1d9&1d9&1d9<7%qtm+2tg$9&;`9&7%qtid#7klj*bizw]_?wt= mi0mf9l0qax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>,3$q,<1f9@l+i4=wwiz*bj[7@.9f3w2tg$9 ml%/mbs0tq<7%9v=gq<5g3$r)b<g)r186%a945%22di+5u=75u=75u4)\"0d*= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=0d+5u=75u9*25%06%lg)b8f)b4q,3$q,3(f)b8f)b4q, m3$q,b8f)b8g)r<g)r<f)b8e,3$q,3`]gq<4t-.u3l!g2/0.[wz5fax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> m,68+\"pl+\"pl+\"z7?>bj[n[m>7ey>7@,#`p->7ez[nrhj*giz>m_?1z4+9f;$ m,3$q,3$qax>ax>ax>ax>as$q,3$qq,3$q,1fq&9f\"pl+i0l+i:6e1t?? m>bj[7ey>`yf9/=)q&1d9l+!3[>v+-,5g#tq,3$r)b8f)b8g)r<g)r<g)%a86 m%a86%a86%a86%a86%a86%a86%a86%lg)r<g)r<f)b4q,3$p/9\\\\7%q<7%q<7% m9v</#tq,3$q,3$q,3$q,3$q,3$q,3$q,3$q,3`]g9v?%q<4t-(om[5-3l+\"p ml!d9<7%q&1fpl+!3l+`9&1eq<7$9&1d9&1d9&1d9&1d9l+\"pl+\"p&1eq<=(] mf5z[*gizw]_?1z6e\"pmfq#&ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>,3$qq,3$9f9f\"z5w]]z m*bj[nux#f9f9f9d]/=(9l+!34^wm[>v+bs0tq6</3$r)b8g)b8g)r<d6%a94 mdi+5u=75u=5\"0d)\"g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g4)\"0d+5u=75u=62de145%06%lg) mb8f)b8e,3$q,3$q,3$q,3$q,3$q,3(f)b8f)b8f)b8f)b8f)b8f)3$q,3`]g mq32+4qd]7bk?i<2ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>,<3$q&9f9@mwrj[n[n[n[m>7ey>7klj m*bhj*bhj*bhj>m]1pmfq,3$q,3$,3$q,3$qax>ax>as$q,8>as$qq&9f m9@mf9f8+\"z6ei:6ei:51t??>bj[7ey>`yd]/=+2tg%q&;\"p4^v+-,5g#tq, m3(f)b8f)b8f)b<g)r<d6%a86%a86%a86%a86%a86%a86%a86%a86%a86%a9, m3$q,3`\\\\/9v=g9v=g9p\\\\/3$q,3(f)b4q,3$q,3(f)b8f)b8f)b8f)b4q,3$p/ m9v?%q<4t-(om4u-34u.pl!d9&1fp4^wm[>u3l!d9<=+2tm)q<1d9l+\"pl+\"p ml%-34u.pl!d9<=*97klj>m]1z6e\"v9f9l0qax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> m,<3$q,1f9@l+i4=wwiz*bhj*kn[7@,#`p.9f9d]/3w2<7$9&1fpl%.+-#3% m9v=g#tq,3$r)b8f)r<d65%22dm75u=75u=5\"g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g4)\"0m75 mu=75u=62di)45%145%14%a86r<g)r<g)r8f)b4q,3$q,3$q,3$q,3$q,3$r) mb8f)b8f)b8f)b8e,3$q,9\\\\6+[;!qf0.[>d<+q(>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax<q,<3$ m9@nei4??>bhj*bj[7ez[n[n[n[n[n[n[n[lj>m]i0mf9l3$q&9f9f9f9l3$ mq,0q,3$q,3$q,3$q,3$q&9f9f8+\"pl+\"pne\"z6ei:6ei4=wwhj*km>7@.9 m/=+2tg%q&1fp4^v+-,5g#tq,3$r)b8f)b8f)r<g)r<g)%a86%a86%a86%a86 m%a86%a86%a86%a86%a9,3$p/#p\\\\/#v=g9p\\\\/#tq,3$q,3$r)b8f)b8f)b8f) mb8f)r<g)r8f)b4q,3$q,3`]gq30tb^wm[8n+bxn+[>wm[>v+bxn+[>u3l+`9 m&1d9l+\"pl+\"pl%-34u/m[5-3l+`9<=*9`[lj>d>e\"pmf9l3$q#&ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>,3$q,<3$9f9f\"z6e1t=w]_?>bhj*bj[n[n[7ex# m`uy>`yf9/=+2tg$9&;!3[>v+-#3%#tq,3(f)r186%e145%145)*2u=750d*= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9u\"0d)\"0m75u=75u=62di*25)*2di*25%145!86r<g)r<g)r8f) mb8f)b8f)3$p/9v=g9v</#tq,3$q,3$q,3$q,3`]gq32+[5.p<=*9`[ljwt<+ m9f8qax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>,<3$9@ne1]_?>bhjn[n[nuy>7ey>nrhj*giz mw]]i:4+\"v9f9f8+\"pl+\"v9fq,0qax>ax>ax>ax<qq,3$9f9f9f9f\"pl+ mi:6ei:6ei:6e1]]z*km>7@,#f9d]/=+2<1fp4^v+bs3%q6=,3$q,b8f)b8g) mr<g)r<g)%a86%a86%a86%a86%a86%a86%a86%a9g#p\\\\/9v=g9v=g#p],3$q, m3(f)b8f)r<g)r<g)r<g)r<g)r<g)b8g)b8f)3$q,#p]g9v=gq<5g#p\\\\/#p]g m9\\\\4t-,5gq<4tbxom[>wm[>v+[8n+b^v+b^wm4[\"p&1d9<3v97kmzwz4+9c& max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>as$q,<3$q,3$q,1f m\"z51]]z*bhj>giz>giz>giz*bhj*bj[`yd]tg%q&;!3[33%9tq,b8f)r<g) mr<d6%a865%14dm75u=75u4*=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=0d)\"0d)\"0d)\"0d+5u=75u=75di)45%065%145%14 m5%145%06%a86%lg)r8f)b8f)b8f)b4q,3`]gq<7%q6=g#v</#p\\\\/#p\\\\/9v=g mq<4tb^vp&=+2tct]f5z[*gii0o$,8>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>as$q&:e1]]z m*kn[7@,#7ey>7ez[n[lj*biz>gk?1z4+\"pl+\"pmf9f9fq,3$q,0q,3&ax> max>ax>,3$q,<3$9f8+\"pl+i:6ei:6ei4=1]]z*kn[7@,#`p.9f3w2<7$9 ml%-3[8n+-,5g#p],3$r)b8f)r<g)r<g)%a86%a86%a86%a86%a86%a86%a9g m9v=g9v=g9p\\\\/3$q,3$r)b8f)r<g)r<g)r<g)%a86%lg)r<g)r<f)b4q,3$q, m3$q,3$q,3$r)b8e,3$q,3$q,3$q,#v=g9\\\\7%q<7%q32+bxn+bxom4[`9&72 mtct#7kmz1z5f,8>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>,3$q,1f9@nei:4+\"pl+i:6ei:6e\"pl+i4=wri>`p.9 mtagm-&</3$q,b8f)b8f)r<g)r186%e145)*2dm75u4*=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g4)\"0d)\"0d)\"u=75u=75u=75u9*2 mdi)45!86%a;)r<g)r1865%145%14%a86%a;)r<g)r<g)b8f)b8f)3$q,#v?% m9v=g9v</#p\\\\/#p\\\\/#p]gq<7%-(om4[`9<7%qtct]`uz[*giz1z6e\"v;$,8> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax<q,<0+i4??>bj[7ey>7ey>7ey>n[n[nrhj>gk?wt>ei:4+ m\"v9f9l3$,3$q,3$qax>ax>ax>ax>ax>,3$qq,1f9@l+i:4+\"pl+\"pl+ mi4=z*bhjn[m>7ey>`yf9/=)q&;\"p4^v+-#3%q6</3$q,b8f)b<g)r<d6%a86 m%a86%a86%a86%a86%a8t-,7%9p\\\\/#tq,3(f)b8g)r<g)r<g)r<g)r<g)r<g) mr<g)b8f)b8f)b8f)b8f)b8f)b8f)b<g)r<f)b8f)b8f)3$q,3$p/9v=gq32+ m[>v+b^u3l!d9&72tcv9`[mz1po$ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>,<1f\"z7?>bi>f=(94xltq<7%q<5g9v=g9p],b<d6%e14dm75u=75 mu4*=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g4)\"0d+5u=75 mu=75u=75u9*2di*25%145!86%a;)r<g)r<g)r<g)r<d6%a86%a86r<g)r<g) mr<g)b8f)b8f)3$q,3$q,3$q,3$q,#p\\\\/#v=gq<7%q<7%-(n+[5.pl+\"pl!eq mtct#7kmzwz6ei:6ei0mf,8>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax?$9j5wwhjn[n[7ey> m7ey>7ez[n[lj>gk?w]]i:4+\"pmf9l3$q#$qax>ax>ax>ax>ax>ax> max<q,3$qq,3$9f9f9l3$q,1f\"z6e1]]z>bhj*kn[7ex#f3w2&1fp4^v+bxn+ m-,5g9p],3$r)b8g)r<g)r186%a86%a86%a86%a8tq<5g#tq,3(f)b8f)b8g) mr<g)r<g)r<g)r<g)b8f)b8f)b<g)r<g)r<g)r<g)r<g)r186%a;)r<g)r<f) mb8f)3$p/#v=g9\\\\4t-(n+[5.p&1eqtcv9f0->nrk?i0o$ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax?$\"z7?>km>`sw2<7$9l%-3[>v+ m-,5g3(f)r1945)*2u=75u4*=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=0d)\"0m75u=75u=75di*2di*2de145!86%a86%lg)r<g)r<d6%a86 m%a86%a86%lg)r<g)r8f)b8f)b8f)b8f)b8f)b8f)b8f)b8e,3$q,#v?%q30t m-(om[>wm[5-3l!d9<72tct#*m]\"\\\\0qas$q,8>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax<qq`nei4??>bhjn[m>7ez[n[n[nriz>m_?1t>ei:4+\"pl+9f;$,3& max>ax>ax>ax>ax>ax>ax>ax>ax<q,3$q,3$q,8<qq&8+i:51t= mwwhj*km>`yd]tad9l%/m[>v+bs3%9p\\\\/3$q,3(f)r<g)r<d6%a86%a86%a;% m9v</3$q,b8f)b8f)b<g)r<g)r<g)r<g)b8f)b<g)r<g)r<d6%a86%a86%a86 m%a86%a86%a86%a86r<f)b8e,3$p/9\\\\4t-(n+[>u3l!g2/0->n[lj*gk?i6;$ max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> mas$\"t??>bj[7@.9f3w2&;!3[8o%3(f)r194di+5u=75u4)\"g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g4)\"0d)\"0d)\"u=75u=75u=75u9*2de145%145%14%a86 mr<g)r8f)b8g)r<g)r<g)%a86%a86%a86%lg)r<f)b8f)b8f)b8e,3$q,3$q, mb8f)b4q,3$qgq<4tbxn+b^wm4[\"p&1eqtm(]f0->7kmz1z5fq#&ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>as$q`ne1t??wwhj*kn[n[n[*bhj*biz m>m]i:4+\"pmf9@l+9l3$,8>ax>ax>ax>ax>ax>ax>ax>ax>ax> mas$q,8>ax<q,<3$9f8+\"pl+i4??>bj[7@,#f=)q&1fpl%/m[33%9p\\\\/3$q, m3(f)b<g)r<d6%a86%a9g#tq,3(f)b8f)b8g)r<g)r<g)r<g)b8f)r<g)r<g) m%a86%a86%a945%145%145%145%145%06%a;)r8f)b4q,3`]gq32+b^wm4[`9 mtid#7kmzwt>e\"\\\\2ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax?$\"z6e1]\\\\j7ig2&5.+q4r)b<g) m%a945)*2di*2di+5u=75u4*=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g4)\"0m75u=75u=75u=75u9*2di*2 mde145!86%a86%a;)r<g)r<f)b4q,3$q,3(f)b<g)r<g)r<g)r<g)r<g)r<g) mr<g)r8f)b4q,3`\\\\/9v</#tq,3$p/9s2+[;`9tm+2tg%qtid#7ez[*gk?w]_? m1t<+q(>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax<qq&9f m\"z5w]]z>bhjn[lj>gizw]_?1z6e\"pl+9f;$,3$,3&ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>,3$q,1f9f9f\"z5wwhjn[m> m`yd]tg$9&;!3[8ltq6</3$q,3(f)r<g)r<g)%a9,b8f)b8f)b8g)r<g)r8f) mr<g)r8f)r<g)r186%a865%145%145%145%145%145%145%145!86r<f)b8e, m3$p/9\\\\7%-(om4qeqtie>nriz1z4+9c&ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max<q9@ne1]\\\\j`suql.v+q6=,b8g)r1;)%a945)+5u4*=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g4)\"0d+5u=75 mu=75u=75u=62di)45!86%a;)r<g)r<g)r<g)r<f)b8f)b8e,3$q,b8f)b<g) mr<g)r8f)r<f)b8f)b8f)b8f)b8f)b4q,#v?%-(om[8n+bxn+[5,9<=(]f0-> m7kn[nriz>m_?1z4+9l2ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>,3$9f8+i:6ei4=1]_?wt=i:6ei0mf9l3$q#& max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> mas$q,3$q&9f9@ne1]]z>bhjnuz9/=)q&;!3[8ltq6</3$q,b8f)r<g)r<f) mb8f)r<g)r8f)b8f)r<g)r<g)r<g)%a86%a945%145%145%22di*2di*2di*2 m5%14%a86r<g)b8f)3$q,3`]gq32+4[`9tie>*d>e\"v;$,8>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>9j7?*ex]tae3bs3%9p],3(f)r<d6 m%e22dm750d)\"g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g4)\"0m75u=75u=75u=75di*25%14%a;)r<g)r<g)r<g)r<g)r<g) mr8f)b4q,3$p/#tq,3(f)b8f)3$q,3$q,3$p/#p\\\\/#tq,3$q,#v?%-(om[5.p ml!d9&1fpl+`9<3v9`uz[*m]1z4+\"v9fq(>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>,<3$q,1f9f9f m9@l+i:4+9f9f9l0qax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>,3$9@ne1t=wwhjnuz9/=)q&5/m mbs3%9p],3$q,3(f)b<g)b8f)b8f)b8f)b8g)r<g)r186%a86%a945%145)*2 mdi*2di*2di*2di*25%145!86%lg)r<f)b8e,3$p/9\\\\4tbu,9/0.[>d<+9l2 max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> mas%fi4??>km>f3uq&;#m-,4/3(g)%e22u=750d*=g9v=g9v=g9v=g9v=g9v= mg9v=g9v=g9v=g9v=g9v=g9v=g9v=g9u\"0m75u=75u=75u=75u9*2de14%lg) mr<g)r<g)r<g)r<g)r<g)r<f)b8f)r8f)b8f)b4q,3$q,#p]g9\\\\4t-#0t-#3% m-#2+bxn+b^wm4u.pl!d9<72/9f9f9f9`uy>nrhj>m]i0mfq#&ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>,3$q,3$q,8>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax<q mq&8+i4??wwj[`yd]tg$9l%/mbs0tq6=g#tq,3(f)b8f)3$r)b8f)b<g)r<d6 m%a865%145%22di*2di*2di*2di*2di*2di)45!86%lg)r<f)b8f)3$p/#\\\\4t m-.t9t@.[>d<+q,0qax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>,<0+wux]&>ug3(g)%a94dm75 mu=5\"0iv=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=g9v=0d)\"0d)\" m0d+5u=75u=75u9*25%06%a86%a86%a86%a86%a;)r<g)r<g)r<g)b8f)b8e, m3`\\\\/9\\\\7%-(n+b^wm[8om[5.pl+\"p&1eq<72/3t]/9f9f0.[*gk?1t>ei:6e mi:6ei0mfq(>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax<q9@l+i4=z*km>`sw2<1fp4^v+bs0tq<5g3$r) m3$q,3(f)b<g)r186%a945%14di*2di*2u=75di*2di*2di*2di)45!86r<g) mr8f)b8e,3$p/9s2+4[`9tif[*m^e9c&ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max?$1[n9&5/%3(f)r186%e22u=75u4)\"0d)\"0m75u=75u=750d*=g9v=g9v= mg9v=g9v=g4)\"0d)\"0d)\"0d)\"u=75u=75u=75di*2di*2di*25%145%06%a86 m%a86%a86%lg)r<f)b8f)3$p/9v=gq32+b^u3l+\"p&1d9&72/3t]/9d#`p,# m`p,#7klj>m_?1z4+9l0q,3$q,3&ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>as$9@ne1]\\\\jnp,# mf3w2tg$9l%/mbs3%9v=,3$r)b8g)r186%e145)*2dm75u=75u=75u=75di*2 mdi*2de145!86%lg)r<f)b4q,#v?%-.u3l!eqtid#nwi\"v8qax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax=fi7j[f7&pbs1g#tr)b<d65%225%145)*2 mu=75u=75u=75u4)\"0d)\"0d+5u=75u=75u=75u=75u=75u=75u=75u=75u=62 mdi*2di*25%145!86%a86%lg)%lg)r<g)r<f)b8e,3$p/9\\\\7%-#2+[>u3l+`9 m&7$9&1eqtcv9f9f9`p->7ez[nrhj*biz>m^e\"\\\\0qax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>,3$9@ne1]\\\\j7@.9/3w2tg$9l%.+-,6)r<g)%a945)*2di*2u=75 mu=75u=75u=75u9*2di*25%145!86%a;)r8f)b4q,9\\\\4tbu,9<=(]/9d#nwk? mi68qax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax?$i=\\\\j7id] mtg$9[31g#tr)b<d6%e145%14%a86%e145)+5u=75di*2di*2di*2di*2di*2 mdi*2di*2di*2di*2di*2di*2de14%a86r<g)r<g)r<g)r<g)b8f)b8f)b8e, m3$q,3$p/9\\\\7%-#2+[>u3l!d9&7%qtm+2tcv9f0->7ez[nrhj>gk?wt>e\"v;$ max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax<q,<1f\"pne1]\\\\j7@.9/3w2tg$9l%,6 m%e14di*2di+5u=75u=75u=75u=75u=75di*25%14%a86%lg)b8e,3$qgq32+ m[;`9tm(]/9d#7biz1z5fax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>a\\\\1f\"z51wj[`](9bv=,3(f)b4q,3$q,3$r)b8f)b<g) mr<g)r<f)b<g)b8f)r<d6%a86%a86%a86r<g)r<g)r<g)r<g)b8e,3`\\\\/#p], m3$r)b8f)3$q,3$q,3$q,3$q,#v=gq<7%q<4t-#2+b^u3l!eq<72/9d#`p-> m7kn[*bhj>gk?w]_?w]^e\"\\\\0qax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax<qq&9f m\"z51whj7@.9/=)q<1f2di*2dm75u=62u=75u=75u=75di*2di*25%06%lg) mr<g)b8e,3&?%-(om4[`9tm+2/9d#nriz1z4+q(>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>as$i7j[7ex#f9f9 mf3t]tm)q&5/m-,7%#tq,b8f)b8f)3$q,3$q,3$q,#p\\\\/3$p/#v=gq30tq<5g m9v=g9\\\\7%-#0tq<7%q<5g9p\\\\/3$q,3$q,3`\\\\/9v=g9v=g9v=g9v=gq<7%-(om m4u-3l!d9&1eqtm(]f0,#`yf9`p->7klj*giz>gk?wt>e\"v;$,8>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax<qq&8+\"t??>bi>`p,]/=*2di*2di*2di*2u=75u=75 mdi*2di)45%06%a86%lg)b8e,3&<t[5-3l!d9<7$]f0->nwk?1pmfq#&ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>as$\"z5>km>`p,]tafp4^wm4u-34u-3[>wml!d9 m&1d9<3t]/7%q&1d9<=*9f=)q<7%q&1fp4u-34u-3[>v+-#0tq<5g#p\\\\/9v=g m9v=g9v?%q<7%q32+b^wm4u-3l+\"pl!d9&7%qtm(]f9d#`yf9`p,#7kn[*biz m>gizw]^e\"v8qax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax<qq&8+i=]z>bj[`yf2 mdi*2di*2di*2di*2di*25%14%a86%a86%a;)b4q,#\\\\6+[;`9<=*9f9d#7ez[ m*m^e\"v;$,3&ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>,<1f\"t??np.9 m/3t]/3t]f0.9f9f9f0->nrj[*biz>bj[n[n[n[lj*kn[*biz*bj[nuy>7ey> m7@,]tg$9l.v+bs0t-,7%q<7%q<7%-#2+b^wm[5-3l!d9&1d9&1d9&1eqtm(] m/9e>7ey>7ey>n[lj*gk?wwizwt=i0mfq(>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax<q9@ne1]]z*ey45%145%145)*2de145%14%a86%a86%lg)b8e,9s2+ m4qg2f0.[*gizwt>e\"pmfq#&ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>,<3$9@nei0l+9l3$q&9f9l0q,3&ax>,<1f9@l+\"z6e m\"v9f9f9f9f8+\"pne1t??>bhj*km>`yd]tg&p4^wmbxlt-#0t-(om[5-3l+\"p ml+`9&1d9&1eqtct]/9d#7ez[*bhj*biz>gk?wt??w]_?w]_?wt=i0mfq(> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax?$9@ne1]]45%145%145%145!86%lg) mr<g)r<f)b4qg-.u3l$]`[mz1z6e\"v;$,3$q,8>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>as$q,3$9f9f9f9f\"z6ei4??*km>`sw2 m<7$9l+!34u-34u.pl+`9&1d9&72tct]tct]/9f9f0,#`p,#7ez[*giz>ghj m*bhj*kn[nrhj>gk?1z4+\"v;$,8>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax?$9j54 m5%145%145!86%lg)r<f)b8e,#\\\\4t[5.p&=*97bk?1z4+9l2ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>as$9@l+i=\\\\jnux#f9f9/3t]tg%q&1d9<7%q&1d9&7%qtm+2tct] m/=+2/9f9`p->n[n[*biz*bj[n[m>7ez[*bizw]]i0l+9l3$,8>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax<q,3$qax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>,<06%a86%a;)r<f)b4q,3`]g-.u3l!eqtid#7bk?i0mf mq#&ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>as$9@mwwhj*kn[nux#`yf9/3w2 mtm)q<7$9&1d9&1d9&1d9&7%q<7%qtct]f0,#7ey>7kn[7ex#`uy>7klj>gk? mi:4+\"v;$,8>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>q&9f\"v;$,8>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>)r<f)b4q,#v?%-.u3l!g2 m/9f9f0->nwii0o$,8>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>,<1f m\"z5w]]z>bj[7ey>`p.9/=)q<7%q&1d9&1d9&1d9&1fpl+\"pl+`9&1eqtcv9 mf0.9f0,#7ey>nriz>m]i0mfq,0qax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> m,3$q#$qax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax=, m#\\\\4t-(oml!eqtcv9`p,#7klj>gk?1z4+q(>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax<qq,3$9f8+i4??>km>`yf9f3w2tm+2tm)q<7%q<7$9 m&1d9&1d9l+\"p&1eq<=+2/3t]/3v9f0,#7ez[*gk?1z6e\"pmfq#&ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax=3l+`9<=(]/9d#7ez[*bizwt>ei0o$,8>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>,6:e1whj*km> m`p.9f3t]tm+2tm)q<7%q<7%q<7%q&1d9&1d9&1d9&1d9&1d9<72/3v9f0,# m7klj>m_?1po$q#$qax>ax>ax>ax>ax>ax>ax>ax>ax<q,3&ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>9f0->7ez[*biz>m]i0mf m9l0qax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax<qq&8+1]]z*kn[nuy>7ex#`yf9/3t]/=+2tm+2tg%q&1d9&1d9 m&1d9&;`9&1d9&7%qtm(]f9f9`p->nrk?1t>e\"v9fq#&ax>ax>ax>ax> max>ax>ax<q,3$q,0qax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax=z mwwizw]_?1z4+\"v;$,8>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>as$q&8+i4??>bhj*bhj*kn[n[n[ mnuy>`p,#`yf9f3t]tm+2<7%q<7%q<7%q<7%q<72tct]f9f9`uz[nrhj*gk? m1t>e\"v;$q#$q,8>,3$q,3&ax>as$qq,3$,3$qax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ei:4+9f;$q,2ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> m,<1f9@l+i:51t??wwiz>giz*bhj*kn[nux#`yf9f3t]/3t]/3t]tm+2tm+2 mtm(]/3t]/9f9f0->7kn[*gizwt>e\"v9f9f9f9f9fq,0q,<3$,8>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax<q,8>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>as$q,3$q,8>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>as$9f9f\"z51]_?w]_?w]]z>bhj*bj[ mnuy>`p,#f9f9f9f9/9f9f0,#`p,#`p,#`p->7kn[*biz>m_?w]_?1t>ei0l+ m\"pl+\"pmf9f;$q,3$,3$q,8>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> mas$q,3$q,3$q,3$q,<3$9f;$9f9f9l3$,3$q,8>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax<q,<1f m\"z6ei:51z51]]z*bhjn[n[*bhj*kn[nuy>7ey>7ez[n[n[n[n[n[n[n[n[ m*bhj>gizw]_?>gk?w]_?1t>ei:4+\"pne\"pmfq,3$,8>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax<q m,3$q,3$q,3$q,3$q,3$9f9f9f9f\"pl+\"v9f9@l+\"pl+\"pmfq,3$,<3$q#$q max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>as$9@l+i:51t??w]_?wwizw]]z>giz>giz>bhj*bj[ mn[n[nrhj*bhj*bhj*bhj*bhj*bhj*giz>giz>gizw]_?1z4+\"pl+\"v9fq,0q m,3&ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax<qq&9f9@l+\"pl+\"v9f9f8+\"z4+\"pl+\"z6ei:51t=i:6ei:6e mi0l+9l3$q,3$,3$q,8>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>as$\"z51t=1t??w]_? mw]_?w]_?w]]z>giz>giz>bhj*bhj*bhj*bhj*bj[n[n[n[n[n[n[nrhj*biz m>gk?wt=i0l+\"v;$q#$qax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>,<1f\"pnei:6e\"z6ei:6ei:6e1t=1t=1t= m1t=1z6ei:6ei4=1t=i0mf9f9f9f;$q#$q,8>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>as$9@l+\"z6ei:6e1t=1t=w]_?w]_?w]_?w]_?>giz>giz>ghj*bhj mn[n[nrhj*bhj*bhj>giz>m_?wt=i0l+9l3$,8>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax<qq&8+i:51z6ei:6e1t= m1]_?>giz>giz>m_?w]_?wt??w]]z>giz>m]1z6ei:6ei:6ei:6ei:6ei:4+ m9c&ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax<qq&9f9f9f\"pl+i:6ei:51t=1t= mw]_?w]_?w]]z>giz>giz*bhj*biz>giz>giz>gk?w]_?1t>e\"v9fq#$qax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>,<1f\"pne mi4=1t=1t>e1t=w]]z>bhjn[n[nrhj*kn[n[n[n[n[7ey>n[lj>gizw]_? mwwiz*bhj*bhj*gizwt<+\"v;$ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> m,3$qq,3$9f9f9@l+i:6ei:6ei4=1t=w]_?wwiz>giz>giz>gizw]_?w]_? mwt=i:4+9l3$,8>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> max>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax>ax> -------- end of part 11 of 14 -------- '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_docs=[doc for doc in dataset.data if doc.find('ax>ax>') != -1]\n",
    "bad_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "I decided to remove these kind of documents. \n",
    "\n",
    "Removing the patterns in the following lines get rid of most of the issues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11299"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data=[doc for doc in dataset.data if doc.find('ax>ax>') == -1]\n",
    "dataset.data=[doc for doc in dataset.data if doc.find('=_') == -1]\n",
    "len(dataset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also remove most punctuation from the documents. \n",
    "\n",
    "I am only keeping commas and full stops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myPunct='!\"#$%&\\'()*+-/:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "documents=[]\n",
    "for doc in dataset.data:\n",
    "    documents.append(\" \".join(\"\".join([ch for ch in doc if ch not in myPunct]).split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a document at random and see how it looks before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  well, there is a fair amount of evidence floating around that indicates that oto has been around since at least the late 1800s, long before crowley ever heard of it, how long has amorc been around? (yes, i know that they claim to have existed as an organization clear into prehistory, but i doubt that they have any organizational paperwork as a non-profit that can be carbon-dated to 20,000 bc)                                              a.lizard '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[124]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'well, there is a fair amount of evidence floating around that indicates that oto has been around since at least the late 1800s, long before crowley ever heard of it, how long has amorc been around yes, i know that they claim to have existed as an organization clear into prehistory, but i doubt that they have any organizational paperwork as a nonprofit that can be carbondated to 20,000 bc a.lizard'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[124]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documents can saved for future use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_documents = open(\"documents_stripped.pickle\", \"wb\")\n",
    "pickle.dump(dataset.data, save_documents)\n",
    "save_documents.close()\n",
    "# open_file = open(\"documents_stripped.pickle\", \"rb\")\n",
    "# documents = pickle.load(open_file)\n",
    "# open_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Document parsing**\n",
    "\n",
    "Load the spacy english package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy is very convenient to use as it does a lot of the heavy lifting with just one call.\n",
    "\n",
    "For example, calling 'nlp(text)' will split the text into sentences, apply part of speech tagging, lemmatization, entity type analysis, punctuation, whitespace and stopword detection and more. \n",
    "\n",
    "Here I create a fucntion, lemmatized_sentence_corpus, that yields lemmatized sentences with no punctuation, whitespaces or stopwords. \n",
    "\n",
    "One thing to note is that I'm removing stopwords twice. First via the punct_space function and later in the function I check the lemmatized tokens again. The reason I do this is that spacy will take words like 'wont' and 'dont' and will lemmatize them to 'will not' and 'do not'. The second pass of stopword removal gets rid of these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def punct_space(token):\n",
    "    return token.is_punct or token.is_space or token.is_stop\n",
    "\n",
    "def lemmatized_sentence_corpus(docs):\n",
    "    for parsed_doc in nlp.pipe(docs):\n",
    "        \n",
    "        for sent in parsed_doc.sents:\n",
    "            token_list=[]\n",
    "            for token in sent:\n",
    "                if not punct_space(token):\n",
    "                    if token.lemma_ == '-PRON-':   #There seems to be a bug in the lemmatizing that assigns '-PRON-' to pronouns \n",
    "                                                   #I will handle the exception here and raise with the package owner \n",
    "                        token_list.append(token.orth_)\n",
    "                    elif token.lemma_ not in spacy.en.STOP_WORDS:\n",
    "                        token_list.append(token.lemma_)\n",
    "            \n",
    "            yield ' '.join(token_list)\n",
    "\n",
    "#Note: spacy takes things like wont and dont and splits them in to will not/do not. Do another stopword removal step here, hopefully that \n",
    "#takes care of the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the 'lemmatized_sentence_corpus' function to the documents and get back a set of sentences.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unigram_sentences=[]\n",
    "for sentence in lemmatized_sentence_corpus(documents):\n",
    "    unigram_sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check a few of the resulting sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sell bike net young lady live salt lake city\n",
      "\n",
      "live near lose angele\n",
      "\n",
      "turn mutual aquaintance ucla\n",
      "\n",
      "uh right\n",
      "\n",
      "forget rbi bar hr base\n",
      "\n",
      "fraction run come solo hr run score happen player base batter good\n",
      "\n",
      "use phrase happen advisedly\n",
      "\n",
      "lot people try figure player ability turn notch clutchrbiwhatever situation find evidence ability measurable extent\n",
      "\n",
      "clutch hitter\n",
      "\n",
      "people tend thing cause rbi somebody base end rbis proportional teammate oblige position agree\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in unigram_sentences[30240:30250]:\n",
    "    print(sent)\n",
    "    print(u'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now that we have the tokenized sentences we can look for pairs of words that appear next to each other more than it would be expected by chance. This words can be joined together to create a bi-gram, i.e., combine them to make a single token that will be more informative to the topic modelling algorithm \n",
    "\n",
    "An example of this could be the words 'ice' and 'cream'. They might be combiined to create an 'ice_cream' token which will provide more information that the single tokens would. \n",
    "\n",
    "The bi-gram transofrmation is performed using the gensim Phrases function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram_sentences = [sent.split(\" \") for sent in unigram_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_model = Phrases(unigram_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venciso\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py36\\lib\\site-packages\\gensim\\models\\phrases.py:316: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bigram_sentences=[]\n",
    "for sentence in unigram_sentences:\n",
    "    bigram_sentences.append(' '.join(bigram_model[sentence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine some of the sentences again now that the bi-grams have been created. \n",
    "\n",
    "The model identified 'salt' and 'lake' as appearing together very frequently and joined them into 'salt_lake'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sell bike net young lady live salt_lake city\n",
      "\n",
      "live near lose angele\n",
      "\n",
      "turn mutual aquaintance ucla\n",
      "\n",
      "uh right\n",
      "\n",
      "forget rbi bar hr base\n",
      "\n",
      "fraction run come solo hr run_score happen player base batter good\n",
      "\n",
      "use phrase happen advisedly\n",
      "\n",
      "lot people try_figure player ability turn notch clutchrbiwhatever situation find evidence ability measurable extent\n",
      "\n",
      "clutch hitter\n",
      "\n",
      "people tend thing cause rbi somebody base end rbis proportional teammate oblige position agree\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in bigram_sentences[30240:30250]:\n",
    "    print(sent)\n",
    "    print(u'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do one more pass and create tri-grams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_sentences = [sent.split(\" \") for sent in bigram_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trigram_model = Phrases(bigram_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venciso\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py36\\lib\\site-packages\\gensim\\models\\phrases.py:316: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trigram_sentences=[]\n",
    "for sentence in bigram_sentences:\n",
    "    trigram_sentences.append(' '.join(trigram_model[sentence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this pass the model now adds 'city' into 'salt_lake' to form a tri-gram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sell bike net young lady live salt_lake_city\n",
      "\n",
      "live near lose angele\n",
      "\n",
      "turn mutual aquaintance ucla\n",
      "\n",
      "uh right\n",
      "\n",
      "forget rbi bar hr base\n",
      "\n",
      "fraction run come solo hr run_score happen player base batter good\n",
      "\n",
      "use phrase happen advisedly\n",
      "\n",
      "lot_people try_figure player ability turn notch clutchrbiwhatever situation find evidence ability measurable extent\n",
      "\n",
      "clutch hitter\n",
      "\n",
      "people tend thing cause rbi somebody base end rbis proportional teammate oblige position agree\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in trigram_sentences[30240:30250]:\n",
    "    print(sent)\n",
    "    print(u'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have finished processing the sentences we can apply the process to the documents using the 'transform_documents' function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_documents(docs):\n",
    "    trigram_transformed_docs = []\n",
    "    for parsed_doc in nlp.pipe(docs):\n",
    "        unigram_doc=[]\n",
    "\n",
    "\n",
    "        for token in parsed_doc:\n",
    "            if not punct_space(token):\n",
    "                if token.lemma_ == '-PRON-':\n",
    "                    unigram_doc.append(token.orth_)\n",
    "                elif token.lemma_ not in spacy.en.STOP_WORDS:\n",
    "                    unigram_doc.append(token.lemma_)\n",
    "\n",
    "        bigram_doc = bigram_model[unigram_doc]\n",
    "        trigram_doc = trigram_model[bigram_doc]\n",
    "        trigram_doc = [term for term in trigram_doc]\n",
    "\n",
    "        trigram_doc = ' '.join(trigram_doc)\n",
    "        trigram_doc = ' '.join( [term for term in trigram_doc.split() if len(term)>1] )\n",
    "\n",
    "        trigram_transformed_docs.append(trigram_doc)\n",
    "    return trigram_transformed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venciso\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py36\\lib\\site-packages\\gensim\\models\\phrases.py:316: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "trigram_transformed_docs = transform_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can examine a document before and after the transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "\n",
      "well im not sure about the story nad it did seem biased. what i disagree with is your statement that the u.s. media is out to ruin israels reputation. that is rediculous. the u.s. media is the most proisraeli media in the world. having lived in europe i realize that incidences such as the one described in the letter have occured. the u.s. media as a whole seem to try to ignore them. the u.s. is subsidizing israels existance and the europeans are not at least not to the same degree. so i think that might be a reason they report more clearly on the atrocities. what is a shame is that in austria, daily reports of the inhuman acts commited by israeli soldiers and the blessing received from the government makes some of the holocaust guilt go away. after all, look how the jews are treating other races when they got power. it is unfortunate.\n",
      "----\n",
      "\n",
      "Transformed:\n",
      "\n",
      "sure story nad biased disagree statement u.s media ruin israel reputation rediculous u.s media proisraeli medium world live europe realize incidence describe letter occur u.s medium try ignore u.s subsidize israel existance european degree think reason report clearly atrocity shame austria daily report inhuman act commit israeli_soldier blessing receive government holocaust guilt away look jew treat race power unfortunate\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "print('Original:' + '\\n')\n",
    "\n",
    "print(documents[i])\n",
    "\n",
    "print ('----' + '\\n')\n",
    "print ('Transformed:' + '\\n')\n",
    "\n",
    "print(trigram_transformed_docs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Topic modelling**\n",
    "\n",
    "We are now ready to take the tokenized tri-gram documents and perform topic modelling.\n",
    "\n",
    "For LDA we will use the gensim package and for NMF we will use scikit-learn.\n",
    "\n",
    "Let's say we have a collection of N documents, LDA assumes that each document is generated by a mixture of topics and that the number of topics is usually small. Also, each topic in turn generates a small set of words. \n",
    "LDA assumes that documents are generated by choosing words according to a multinomial distributions (one for topics and one for words in the topics) whose hypeparamters are governed by sparse Dirichlet priors (this basically encodes the 'small' concept in the previous paragraph).\n",
    "LDA the tries to backtrack from this process to find a set of topics that are likely to have generated the documents. \n",
    "\n",
    "NMF represents the set of documents as a matrix X of size N (documents) columns and M (words) rows. It then tries to find two non-negative matrices W and H such that their product approximates X as well as possible. W is an N by K and H is K by N so it can be seen that K is the number of topics.\n",
    "\n",
    "LDA has a frequentist version called probabilistic latent semantic analysis (pLSA). NMF and pLSA are equivalent and the main difference between them and LDA is the sparsity introduced by the Dirichlet priors.\n",
    "LDA has more control over the way the topics are specified since one can modify the prior hyperparameters to achieve more or less distinct topics. \n",
    "\n",
    "\n",
    "In both LDA and NMF techniques the user has to specify the number of topics in the model. While researching online there does not seem to be a definitive way to determine the number of topics. Using the perplexitiy statistic or some sort of elbow method similar to what is used in cluster analysis are some of the ideas I found but there doesn't seem to be a general consensus on these. \n",
    "\n",
    "For this reason and given that we know the data is generated from 20 newsgroups I will choose 20 as the obvious choice for the number of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models import LdaModel,TfidfModel\n",
    "from gensim.matutils import cossim\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For LDA modelling we need to create a dictionary of all the tokens. \n",
    "\n",
    "We then filter out the tokens that are either very common or very rare or we can decide to keep a certan number of tokens. \n",
    "\n",
    "From the dictionary we can create a bag of words which have all the tokens that we kept and how many times they occur in each document. \n",
    "\n",
    "The resulting bag of words corpus can be fed into the lda model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trigram_docs = [doc.split(\" \") for doc in trigram_transformed_docs]\n",
    "\n",
    "trigram_dictionary=Dictionary(trigram_docs)\n",
    "\n",
    "trigram_dictionary.filter_extremes(no_above=0.5,no_below=10,keep_n=5000)\n",
    "trigram_dictionary.compactify()\n",
    "\n",
    "trigram_bow_corpus=[trigram_dictionary.doc2bow(doc) for doc in trigram_docs]\n",
    "\n",
    "lda=LdaModel(trigram_bow_corpus,num_topics=20,id2word=trigram_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alpha parameter controls the sparsity of the document to topic priors. It is usually set to a deafult value of 1 / number_of_topics.\n",
    "\n",
    "Run a version of the model with an alpha > 1 to explore the behaviour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda_a=LdaModel(trigram_bow_corpus,num_topics=20,id2word=trigram_dictionary,alpha=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform NMF we need a term-frequency inverse-document-frequency representation. \n",
    "\n",
    "We first use TfidfVectorizer to decide the features in the model. The nuber of features we will use will be the same as for LDA. \n",
    "\n",
    "We then transform the documents and feed them into the NMF function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trigram_transformed_docs_str=[str(text) for text in trigram_transformed_docs]\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=10, max_df=0.8,max_features=5000)\n",
    "tfidf = tfidf_vectorizer.fit_transform(trigram_transformed_docs_str)\n",
    "\n",
    "nmf = NMF(n_components=20,init='nndsvd').fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define functions to explore the topics generated by each algorithm. \n",
    "\n",
    "For each of the topics we show the top n most important terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_lda_topics(model,num_topics,n_top_words):\n",
    "    word_dict = {};\n",
    "    for i in range(num_topics):\n",
    "        words = eval(\"{}.show_topic(i, topn = n_top_words)\".format(model))\n",
    "        word_dict['Topic # ' + '{:02d}'.format(i+1)] = [i[0] for i in words];\n",
    "    return pd.DataFrame(word_dict);\n",
    "\n",
    "def get_nmf_topics(model,num_topics,n_top_words):\n",
    "    feat_names = tfidf_vectorizer.get_feature_names()\n",
    "    word_dict = {};\n",
    "    for i in range(num_topics):\n",
    "        words_ids = eval(\"{}.components_[i].argsort()[:-n_top_words - 1:-1]\".format(model))\n",
    "        words = [feat_names[key] for key in words_ids]\n",
    "        word_dict['Topic # ' + '{:02d}'.format(i+1)] = words;\n",
    "    \n",
    "    return pd.DataFrame(word_dict);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LDA topics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic # 01</th>\n",
       "      <th>Topic # 02</th>\n",
       "      <th>Topic # 03</th>\n",
       "      <th>Topic # 04</th>\n",
       "      <th>Topic # 05</th>\n",
       "      <th>Topic # 06</th>\n",
       "      <th>Topic # 07</th>\n",
       "      <th>Topic # 08</th>\n",
       "      <th>Topic # 09</th>\n",
       "      <th>Topic # 10</th>\n",
       "      <th>Topic # 11</th>\n",
       "      <th>Topic # 12</th>\n",
       "      <th>Topic # 13</th>\n",
       "      <th>Topic # 14</th>\n",
       "      <th>Topic # 15</th>\n",
       "      <th>Topic # 16</th>\n",
       "      <th>Topic # 17</th>\n",
       "      <th>Topic # 18</th>\n",
       "      <th>Topic # 19</th>\n",
       "      <th>Topic # 20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>key</td>\n",
       "      <td>entry</td>\n",
       "      <td>think</td>\n",
       "      <td>gun</td>\n",
       "      <td>think</td>\n",
       "      <td>law</td>\n",
       "      <td>day</td>\n",
       "      <td>armenian</td>\n",
       "      <td>game</td>\n",
       "      <td>program</td>\n",
       "      <td>thank</td>\n",
       "      <td>good</td>\n",
       "      <td>program</td>\n",
       "      <td>god</td>\n",
       "      <td>think</td>\n",
       "      <td>10</td>\n",
       "      <td>use</td>\n",
       "      <td>jew</td>\n",
       "      <td>drive</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>use</td>\n",
       "      <td></td>\n",
       "      <td>good</td>\n",
       "      <td>use</td>\n",
       "      <td>know</td>\n",
       "      <td>pain</td>\n",
       "      <td>power</td>\n",
       "      <td>people</td>\n",
       "      <td>team</td>\n",
       "      <td>available</td>\n",
       "      <td>post</td>\n",
       "      <td>car</td>\n",
       "      <td>work</td>\n",
       "      <td>people</td>\n",
       "      <td>problem</td>\n",
       "      <td>12</td>\n",
       "      <td>window</td>\n",
       "      <td>jewish</td>\n",
       "      <td>pin</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>system</td>\n",
       "      <td>file</td>\n",
       "      <td>know</td>\n",
       "      <td>people</td>\n",
       "      <td>people</td>\n",
       "      <td>patient</td>\n",
       "      <td>think</td>\n",
       "      <td>president</td>\n",
       "      <td>year</td>\n",
       "      <td>include</td>\n",
       "      <td>memory</td>\n",
       "      <td>time</td>\n",
       "      <td>line</td>\n",
       "      <td>know</td>\n",
       "      <td>time</td>\n",
       "      <td>11</td>\n",
       "      <td>system</td>\n",
       "      <td>israel</td>\n",
       "      <td>jumper</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chip</td>\n",
       "      <td>program</td>\n",
       "      <td>player</td>\n",
       "      <td>time</td>\n",
       "      <td>like</td>\n",
       "      <td>doctor</td>\n",
       "      <td>time</td>\n",
       "      <td>russian</td>\n",
       "      <td>good</td>\n",
       "      <td>version</td>\n",
       "      <td>address</td>\n",
       "      <td>like</td>\n",
       "      <td>file</td>\n",
       "      <td>christian</td>\n",
       "      <td>know</td>\n",
       "      <td>15</td>\n",
       "      <td>problem</td>\n",
       "      <td>state</td>\n",
       "      <td>gm</td>\n",
       "      <td>israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new</td>\n",
       "      <td>driver</td>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "      <td>believe</td>\n",
       "      <td>disease</td>\n",
       "      <td>water</td>\n",
       "      <td>turkish</td>\n",
       "      <td>win</td>\n",
       "      <td>information</td>\n",
       "      <td>motherboard</td>\n",
       "      <td>look</td>\n",
       "      <td>know</td>\n",
       "      <td>jesus</td>\n",
       "      <td>good</td>\n",
       "      <td>13</td>\n",
       "      <td>file</td>\n",
       "      <td>claim</td>\n",
       "      <td>insert</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>car</td>\n",
       "      <td>function</td>\n",
       "      <td>people</td>\n",
       "      <td>work</td>\n",
       "      <td>exist</td>\n",
       "      <td>tax</td>\n",
       "      <td>know</td>\n",
       "      <td>government</td>\n",
       "      <td>play</td>\n",
       "      <td>file</td>\n",
       "      <td>scsi</td>\n",
       "      <td>bike</td>\n",
       "      <td>use</td>\n",
       "      <td>think</td>\n",
       "      <td>science</td>\n",
       "      <td>14</td>\n",
       "      <td>know</td>\n",
       "      <td>israeli</td>\n",
       "      <td>italy</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>price</td>\n",
       "      <td>work</td>\n",
       "      <td>case</td>\n",
       "      <td>good</td>\n",
       "      <td>want</td>\n",
       "      <td>state</td>\n",
       "      <td>space</td>\n",
       "      <td>think</td>\n",
       "      <td>season</td>\n",
       "      <td>server</td>\n",
       "      <td>system</td>\n",
       "      <td>right</td>\n",
       "      <td>like</td>\n",
       "      <td>believe</td>\n",
       "      <td>objective</td>\n",
       "      <td>16</td>\n",
       "      <td>work</td>\n",
       "      <td>question</td>\n",
       "      <td>doug</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>datum</td>\n",
       "      <td>set</td>\n",
       "      <td>point</td>\n",
       "      <td>know</td>\n",
       "      <td>way</td>\n",
       "      <td>know</td>\n",
       "      <td>easter</td>\n",
       "      <td>mr</td>\n",
       "      <td>player</td>\n",
       "      <td>use</td>\n",
       "      <td>list</td>\n",
       "      <td>come</td>\n",
       "      <td>year</td>\n",
       "      <td>come</td>\n",
       "      <td>true</td>\n",
       "      <td>25</td>\n",
       "      <td>run</td>\n",
       "      <td>post</td>\n",
       "      <td>slave</td>\n",
       "      <td>kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>phone</td>\n",
       "      <td>try</td>\n",
       "      <td>thing</td>\n",
       "      <td>want</td>\n",
       "      <td>find</td>\n",
       "      <td>year</td>\n",
       "      <td>work</td>\n",
       "      <td>city</td>\n",
       "      <td>hit</td>\n",
       "      <td>widget</td>\n",
       "      <td>include</td>\n",
       "      <td>think</td>\n",
       "      <td>post</td>\n",
       "      <td>thing</td>\n",
       "      <td>moral</td>\n",
       "      <td>20</td>\n",
       "      <td>display</td>\n",
       "      <td>force</td>\n",
       "      <td>setup</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>know</td>\n",
       "      <td>find</td>\n",
       "      <td>right</td>\n",
       "      <td>think</td>\n",
       "      <td>mean</td>\n",
       "      <td>medical</td>\n",
       "      <td>good</td>\n",
       "      <td>turkey</td>\n",
       "      <td>like</td>\n",
       "      <td>source</td>\n",
       "      <td>clone</td>\n",
       "      <td>way</td>\n",
       "      <td>group</td>\n",
       "      <td>word</td>\n",
       "      <td>like</td>\n",
       "      <td>18</td>\n",
       "      <td>software</td>\n",
       "      <td>article</td>\n",
       "      <td>17</td>\n",
       "      <td>tell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic # 01 Topic # 02 Topic # 03 Topic # 04 Topic # 05 Topic # 06  \\\n",
       "0        key      entry      think        gun      think        law   \n",
       "1        use                  good        use       know       pain   \n",
       "2     system       file       know     people     people    patient   \n",
       "3       chip    program     player       time       like     doctor   \n",
       "4        new     driver       like       like    believe    disease   \n",
       "5        car   function     people       work      exist        tax   \n",
       "6      price       work       case       good       want      state   \n",
       "7      datum        set      point       know        way       know   \n",
       "8      phone        try      thing       want       find       year   \n",
       "9       know       find      right      think       mean    medical   \n",
       "\n",
       "  Topic # 07  Topic # 08 Topic # 09   Topic # 10   Topic # 11 Topic # 12  \\\n",
       "0        day    armenian       game      program        thank       good   \n",
       "1      power      people       team    available         post        car   \n",
       "2      think   president       year      include       memory       time   \n",
       "3       time     russian       good      version      address       like   \n",
       "4      water     turkish        win  information  motherboard       look   \n",
       "5       know  government       play         file         scsi       bike   \n",
       "6      space       think     season       server       system      right   \n",
       "7     easter          mr     player          use         list       come   \n",
       "8       work        city        hit       widget      include      think   \n",
       "9       good      turkey       like       source        clone        way   \n",
       "\n",
       "  Topic # 13 Topic # 14 Topic # 15 Topic # 16 Topic # 17 Topic # 18  \\\n",
       "0    program        god      think         10        use        jew   \n",
       "1       work     people    problem         12     window     jewish   \n",
       "2       line       know       time         11     system     israel   \n",
       "3       file  christian       know         15    problem      state   \n",
       "4       know      jesus       good         13       file      claim   \n",
       "5        use      think    science         14       know    israeli   \n",
       "6       like    believe  objective         16       work   question   \n",
       "7       year       come       true         25        run       post   \n",
       "8       post      thing      moral         20    display      force   \n",
       "9      group       word       like         18   software    article   \n",
       "\n",
       "  Topic # 19 Topic # 20  \n",
       "0      drive       know  \n",
       "1        pin     people  \n",
       "2     jumper       like  \n",
       "3         gm     israel  \n",
       "4     insert       want  \n",
       "5      italy    problem  \n",
       "6       doug       time  \n",
       "7      slave       kill  \n",
       "8      setup      right  \n",
       "9         17       tell  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lda_topics('lda',20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic # 01</th>\n",
       "      <th>Topic # 02</th>\n",
       "      <th>Topic # 03</th>\n",
       "      <th>Topic # 04</th>\n",
       "      <th>Topic # 05</th>\n",
       "      <th>Topic # 06</th>\n",
       "      <th>Topic # 07</th>\n",
       "      <th>Topic # 08</th>\n",
       "      <th>Topic # 09</th>\n",
       "      <th>Topic # 10</th>\n",
       "      <th>Topic # 11</th>\n",
       "      <th>Topic # 12</th>\n",
       "      <th>Topic # 13</th>\n",
       "      <th>Topic # 14</th>\n",
       "      <th>Topic # 15</th>\n",
       "      <th>Topic # 16</th>\n",
       "      <th>Topic # 17</th>\n",
       "      <th>Topic # 18</th>\n",
       "      <th>Topic # 19</th>\n",
       "      <th>Topic # 20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>know</td>\n",
       "      <td>know</td>\n",
       "      <td>think</td>\n",
       "      <td>like</td>\n",
       "      <td>use</td>\n",
       "      <td>god</td>\n",
       "      <td>people</td>\n",
       "      <td>like</td>\n",
       "      <td>know</td>\n",
       "      <td>file</td>\n",
       "      <td>know</td>\n",
       "      <td>know</td>\n",
       "      <td>know</td>\n",
       "      <td>think</td>\n",
       "      <td>good</td>\n",
       "      <td>people</td>\n",
       "      <td>know</td>\n",
       "      <td>game</td>\n",
       "      <td>think</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>like</td>\n",
       "      <td>good</td>\n",
       "      <td>people</td>\n",
       "      <td>know</td>\n",
       "      <td>run</td>\n",
       "      <td>christian</td>\n",
       "      <td>armenian</td>\n",
       "      <td>think</td>\n",
       "      <td>good</td>\n",
       "      <td>program</td>\n",
       "      <td>like</td>\n",
       "      <td>armenian</td>\n",
       "      <td>think</td>\n",
       "      <td>know</td>\n",
       "      <td>think</td>\n",
       "      <td>know</td>\n",
       "      <td>time</td>\n",
       "      <td>team</td>\n",
       "      <td>work</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>think</td>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "      <td>good</td>\n",
       "      <td>system</td>\n",
       "      <td>jesus</td>\n",
       "      <td>turkish</td>\n",
       "      <td>know</td>\n",
       "      <td>think</td>\n",
       "      <td>use</td>\n",
       "      <td>good</td>\n",
       "      <td>people</td>\n",
       "      <td>time</td>\n",
       "      <td>good</td>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "      <td>good</td>\n",
       "      <td>10</td>\n",
       "      <td>know</td>\n",
       "      <td>think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>think</td>\n",
       "      <td>know</td>\n",
       "      <td>think</td>\n",
       "      <td>program</td>\n",
       "      <td>people</td>\n",
       "      <td>jew</td>\n",
       "      <td>people</td>\n",
       "      <td>like</td>\n",
       "      <td>include</td>\n",
       "      <td>use</td>\n",
       "      <td>come</td>\n",
       "      <td>good</td>\n",
       "      <td>like</td>\n",
       "      <td>know</td>\n",
       "      <td>good</td>\n",
       "      <td>use</td>\n",
       "      <td>win</td>\n",
       "      <td>time</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>people</td>\n",
       "      <td>people</td>\n",
       "      <td>good</td>\n",
       "      <td>use</td>\n",
       "      <td>window</td>\n",
       "      <td>think</td>\n",
       "      <td>know</td>\n",
       "      <td>good</td>\n",
       "      <td>time</td>\n",
       "      <td>available</td>\n",
       "      <td>work</td>\n",
       "      <td>tell</td>\n",
       "      <td>people</td>\n",
       "      <td>people</td>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "      <td>gun</td>\n",
       "      <td>12</td>\n",
       "      <td>people</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>work</td>\n",
       "      <td>problem</td>\n",
       "      <td>time</td>\n",
       "      <td>want</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>turkey</td>\n",
       "      <td>time</td>\n",
       "      <td>year</td>\n",
       "      <td>information</td>\n",
       "      <td>think</td>\n",
       "      <td>think</td>\n",
       "      <td>like</td>\n",
       "      <td>use</td>\n",
       "      <td>people</td>\n",
       "      <td>use</td>\n",
       "      <td>people</td>\n",
       "      <td>14</td>\n",
       "      <td>use</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>people</td>\n",
       "      <td>problem</td>\n",
       "      <td>believe</td>\n",
       "      <td>like</td>\n",
       "      <td>work</td>\n",
       "      <td>people</td>\n",
       "      <td>system</td>\n",
       "      <td>people</td>\n",
       "      <td>time</td>\n",
       "      <td>problem</td>\n",
       "      <td>problem</td>\n",
       "      <td>work</td>\n",
       "      <td>problem</td>\n",
       "      <td>file</td>\n",
       "      <td>13</td>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>way</td>\n",
       "      <td>want</td>\n",
       "      <td>work</td>\n",
       "      <td>try</td>\n",
       "      <td>line</td>\n",
       "      <td>thing</td>\n",
       "      <td>time</td>\n",
       "      <td>want</td>\n",
       "      <td>way</td>\n",
       "      <td>software</td>\n",
       "      <td>thing</td>\n",
       "      <td>like</td>\n",
       "      <td>want</td>\n",
       "      <td>want</td>\n",
       "      <td>try</td>\n",
       "      <td>way</td>\n",
       "      <td>year</td>\n",
       "      <td>11</td>\n",
       "      <td>good</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>try</td>\n",
       "      <td>work</td>\n",
       "      <td>want</td>\n",
       "      <td>time</td>\n",
       "      <td>include</td>\n",
       "      <td>way</td>\n",
       "      <td>good</td>\n",
       "      <td>use</td>\n",
       "      <td>work</td>\n",
       "      <td>image</td>\n",
       "      <td>want</td>\n",
       "      <td>want</td>\n",
       "      <td>thing</td>\n",
       "      <td>way</td>\n",
       "      <td>use</td>\n",
       "      <td>think</td>\n",
       "      <td>like</td>\n",
       "      <td>15</td>\n",
       "      <td>want</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>look</td>\n",
       "      <td>find</td>\n",
       "      <td>way</td>\n",
       "      <td>work</td>\n",
       "      <td>work</td>\n",
       "      <td>know</td>\n",
       "      <td>think</td>\n",
       "      <td>problem</td>\n",
       "      <td>want</td>\n",
       "      <td>version</td>\n",
       "      <td>time</td>\n",
       "      <td>kill</td>\n",
       "      <td>try</td>\n",
       "      <td>time</td>\n",
       "      <td>system</td>\n",
       "      <td>find</td>\n",
       "      <td>think</td>\n",
       "      <td>16</td>\n",
       "      <td>program</td>\n",
       "      <td>thing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic # 01 Topic # 02 Topic # 03 Topic # 04 Topic # 05 Topic # 06  \\\n",
       "0       know       know      think       like        use        god   \n",
       "1       like       good     people       know        run  christian   \n",
       "2      think       like       like       good     system      jesus   \n",
       "3       good      think       know      think    program     people   \n",
       "4     people     people       good        use     window      think   \n",
       "5       work    problem       time       want       good       good   \n",
       "6       time        use        use     people    problem    believe   \n",
       "7        way       want       work        try       line      thing   \n",
       "8        try       work       want       time    include        way   \n",
       "9       look       find        way       work       work       know   \n",
       "\n",
       "  Topic # 07 Topic # 08 Topic # 09   Topic # 10 Topic # 11 Topic # 12  \\\n",
       "0     people       like       know         file       know       know   \n",
       "1   armenian      think       good      program       like   armenian   \n",
       "2    turkish       know      think          use       good     people   \n",
       "3        jew     people       like      include        use       come   \n",
       "4       know       good       time    available       work       tell   \n",
       "5     turkey       time       year  information      think      think   \n",
       "6       like       work     people       system     people       time   \n",
       "7       time       want        way     software      thing       like   \n",
       "8       good        use       work        image       want       want   \n",
       "9      think    problem       want      version       time       kill   \n",
       "\n",
       "  Topic # 13 Topic # 14 Topic # 15 Topic # 16 Topic # 17 Topic # 18  \\\n",
       "0       know      think       good     people       know       game   \n",
       "1      think       know      think       know       time       team   \n",
       "2       time       good       like       like       good         10   \n",
       "3       good       like       know       good        use        win   \n",
       "4     people     people       time       time        gun         12   \n",
       "5       like        use     people        use     people         14   \n",
       "6    problem    problem       work    problem       file         13   \n",
       "7       want       want        try        way       year         11   \n",
       "8      thing        way        use      think       like         15   \n",
       "9        try       time     system       find      think         16   \n",
       "\n",
       "  Topic # 19 Topic # 20  \n",
       "0      think       good  \n",
       "1       work       time  \n",
       "2       know      think  \n",
       "3       time       work  \n",
       "4     people        use  \n",
       "5        use       want  \n",
       "6       like       like  \n",
       "7       good       know  \n",
       "8       want     people  \n",
       "9    program      thing  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lda_topics('lda_a',20,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the effect of changing the alpha parameter by examining terms like 'think' or 'time'. These terms appear in the top words of a few of the topics of the 'lda' model but they appear in almost every topic in 'lda_a'.\n",
    "\n",
    "The default parameter for alpha is 1/n_topics, more sparcity could be introduced if desired by making this smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NMF topics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic # 01</th>\n",
       "      <th>Topic # 02</th>\n",
       "      <th>Topic # 03</th>\n",
       "      <th>Topic # 04</th>\n",
       "      <th>Topic # 05</th>\n",
       "      <th>Topic # 06</th>\n",
       "      <th>Topic # 07</th>\n",
       "      <th>Topic # 08</th>\n",
       "      <th>Topic # 09</th>\n",
       "      <th>Topic # 10</th>\n",
       "      <th>Topic # 11</th>\n",
       "      <th>Topic # 12</th>\n",
       "      <th>Topic # 13</th>\n",
       "      <th>Topic # 14</th>\n",
       "      <th>Topic # 15</th>\n",
       "      <th>Topic # 16</th>\n",
       "      <th>Topic # 17</th>\n",
       "      <th>Topic # 18</th>\n",
       "      <th>Topic # 19</th>\n",
       "      <th>Topic # 20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people</td>\n",
       "      <td>window</td>\n",
       "      <td>game</td>\n",
       "      <td>time</td>\n",
       "      <td>god</td>\n",
       "      <td>thank</td>\n",
       "      <td>chastity_intellect_gebcadre</td>\n",
       "      <td>key</td>\n",
       "      <td>car</td>\n",
       "      <td>israel</td>\n",
       "      <td>think</td>\n",
       "      <td>drive</td>\n",
       "      <td>know</td>\n",
       "      <td>edu</td>\n",
       "      <td>file</td>\n",
       "      <td>card</td>\n",
       "      <td>good</td>\n",
       "      <td>com</td>\n",
       "      <td>bike</td>\n",
       "      <td>look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>right</td>\n",
       "      <td>program</td>\n",
       "      <td>team</td>\n",
       "      <td>post</td>\n",
       "      <td>christian</td>\n",
       "      <td>hi</td>\n",
       "      <td>surrender_soon</td>\n",
       "      <td>chip</td>\n",
       "      <td>engine</td>\n",
       "      <td>armenian</td>\n",
       "      <td>like</td>\n",
       "      <td>scsi</td>\n",
       "      <td>want</td>\n",
       "      <td>00</td>\n",
       "      <td>directory</td>\n",
       "      <td>problem</td>\n",
       "      <td>bad</td>\n",
       "      <td>article</td>\n",
       "      <td>ride</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>government</td>\n",
       "      <td>run</td>\n",
       "      <td>player</td>\n",
       "      <td>work</td>\n",
       "      <td>jesus</td>\n",
       "      <td>email</td>\n",
       "      <td>edu_shameful</td>\n",
       "      <td>use</td>\n",
       "      <td>price</td>\n",
       "      <td>arab</td>\n",
       "      <td>guy</td>\n",
       "      <td>disk</td>\n",
       "      <td>like</td>\n",
       "      <td>sale</td>\n",
       "      <td>zip</td>\n",
       "      <td>driver</td>\n",
       "      <td>thing</td>\n",
       "      <td>list</td>\n",
       "      <td>motorcycle</td>\n",
       "      <td>information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gun</td>\n",
       "      <td>use</td>\n",
       "      <td>play</td>\n",
       "      <td>find</td>\n",
       "      <td>bible</td>\n",
       "      <td>information</td>\n",
       "      <td>dsl</td>\n",
       "      <td>system</td>\n",
       "      <td>dealer</td>\n",
       "      <td>israeli</td>\n",
       "      <td>mean</td>\n",
       "      <td>jumper</td>\n",
       "      <td>thank_advance</td>\n",
       "      <td>email</td>\n",
       "      <td>format</td>\n",
       "      <td>system</td>\n",
       "      <td>player</td>\n",
       "      <td>sun</td>\n",
       "      <td>mile</td>\n",
       "      <td>thank_advance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>law</td>\n",
       "      <td>application</td>\n",
       "      <td>year</td>\n",
       "      <td>like</td>\n",
       "      <td>believe</td>\n",
       "      <td>info</td>\n",
       "      <td>gordon_bank_n3jxp_skepticism</td>\n",
       "      <td>government</td>\n",
       "      <td>new</td>\n",
       "      <td>jew</td>\n",
       "      <td>way</td>\n",
       "      <td>boot</td>\n",
       "      <td>hear</td>\n",
       "      <td>sell</td>\n",
       "      <td>convert</td>\n",
       "      <td>monitor</td>\n",
       "      <td>year</td>\n",
       "      <td>email</td>\n",
       "      <td>helmet</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>state</td>\n",
       "      <td>display</td>\n",
       "      <td>win</td>\n",
       "      <td>group</td>\n",
       "      <td>faith</td>\n",
       "      <td>appreciate</td>\n",
       "      <td>pitt</td>\n",
       "      <td>encryption</td>\n",
       "      <td>mile</td>\n",
       "      <td>kill</td>\n",
       "      <td>wrong</td>\n",
       "      <td>format</td>\n",
       "      <td>sure</td>\n",
       "      <td>offer</td>\n",
       "      <td>disk</td>\n",
       "      <td>work</td>\n",
       "      <td>way</td>\n",
       "      <td>reply</td>\n",
       "      <td>sell</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>country</td>\n",
       "      <td>font</td>\n",
       "      <td>season</td>\n",
       "      <td>read</td>\n",
       "      <td>religion</td>\n",
       "      <td>interested</td>\n",
       "      <td>patient</td>\n",
       "      <td>nsa</td>\n",
       "      <td>model</td>\n",
       "      <td>jewish</td>\n",
       "      <td>yes</td>\n",
       "      <td>switch</td>\n",
       "      <td>thing</td>\n",
       "      <td>include</td>\n",
       "      <td>exe</td>\n",
       "      <td>apple</td>\n",
       "      <td>lot</td>\n",
       "      <td>internet</td>\n",
       "      <td>rid</td>\n",
       "      <td>find</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mean</td>\n",
       "      <td>server</td>\n",
       "      <td>fan</td>\n",
       "      <td>new</td>\n",
       "      <td>sin</td>\n",
       "      <td>find</td>\n",
       "      <td>migraine</td>\n",
       "      <td>clipper</td>\n",
       "      <td>tire</td>\n",
       "      <td>palestinian</td>\n",
       "      <td>believe</td>\n",
       "      <td>cable</td>\n",
       "      <td>tell</td>\n",
       "      <td>send</td>\n",
       "      <td>ftp</td>\n",
       "      <td>mode</td>\n",
       "      <td>point</td>\n",
       "      <td>quote</td>\n",
       "      <td>honda</td>\n",
       "      <td>interested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>want</td>\n",
       "      <td>screen</td>\n",
       "      <td>hockey</td>\n",
       "      <td>space</td>\n",
       "      <td>christ</td>\n",
       "      <td>need</td>\n",
       "      <td>probably</td>\n",
       "      <td>phone</td>\n",
       "      <td>ford</td>\n",
       "      <td>attack</td>\n",
       "      <td>lot</td>\n",
       "      <td>hard_drive</td>\n",
       "      <td>maybe</td>\n",
       "      <td>ftp</td>\n",
       "      <td>program</td>\n",
       "      <td>machine</td>\n",
       "      <td>use</td>\n",
       "      <td>address</td>\n",
       "      <td>buy</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>person</td>\n",
       "      <td>version</td>\n",
       "      <td>score</td>\n",
       "      <td>try</td>\n",
       "      <td>life</td>\n",
       "      <td>send</td>\n",
       "      <td>weight</td>\n",
       "      <td>algorithm</td>\n",
       "      <td>power</td>\n",
       "      <td>war</td>\n",
       "      <td>thing</td>\n",
       "      <td>ide</td>\n",
       "      <td>ne</td>\n",
       "      <td>mit</td>\n",
       "      <td>download</td>\n",
       "      <td>memory</td>\n",
       "      <td>buy</td>\n",
       "      <td>hp</td>\n",
       "      <td>turn</td>\n",
       "      <td>package</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic # 01   Topic # 02 Topic # 03 Topic # 04 Topic # 05   Topic # 06  \\\n",
       "0      people       window       game       time        god        thank   \n",
       "1       right      program       team       post  christian           hi   \n",
       "2  government          run     player       work      jesus        email   \n",
       "3         gun          use       play       find      bible  information   \n",
       "4         law  application       year       like    believe         info   \n",
       "5       state      display        win      group      faith   appreciate   \n",
       "6     country         font     season       read   religion   interested   \n",
       "7        mean       server        fan        new        sin         find   \n",
       "8        want       screen     hockey      space     christ         need   \n",
       "9      person      version      score        try       life         send   \n",
       "\n",
       "                     Topic # 07  Topic # 08 Topic # 09   Topic # 10  \\\n",
       "0   chastity_intellect_gebcadre         key        car       israel   \n",
       "1                surrender_soon        chip     engine     armenian   \n",
       "2                  edu_shameful         use      price         arab   \n",
       "3                           dsl      system     dealer      israeli   \n",
       "4  gordon_bank_n3jxp_skepticism  government        new          jew   \n",
       "5                          pitt  encryption       mile         kill   \n",
       "6                       patient         nsa      model       jewish   \n",
       "7                      migraine     clipper       tire  palestinian   \n",
       "8                      probably       phone       ford       attack   \n",
       "9                        weight   algorithm      power          war   \n",
       "\n",
       "  Topic # 11  Topic # 12     Topic # 13 Topic # 14 Topic # 15 Topic # 16  \\\n",
       "0      think       drive           know        edu       file       card   \n",
       "1       like        scsi           want         00  directory    problem   \n",
       "2        guy        disk           like       sale        zip     driver   \n",
       "3       mean      jumper  thank_advance      email     format     system   \n",
       "4        way        boot           hear       sell    convert    monitor   \n",
       "5      wrong      format           sure      offer       disk       work   \n",
       "6        yes      switch          thing    include        exe      apple   \n",
       "7    believe       cable           tell       send        ftp       mode   \n",
       "8        lot  hard_drive          maybe        ftp    program    machine   \n",
       "9      thing         ide             ne        mit   download     memory   \n",
       "\n",
       "  Topic # 17 Topic # 18  Topic # 19     Topic # 20  \n",
       "0       good        com        bike           look  \n",
       "1        bad    article        ride          email  \n",
       "2      thing       list  motorcycle    information  \n",
       "3     player        sun        mile  thank_advance  \n",
       "4       year      email      helmet            buy  \n",
       "5        way      reply        sell           want  \n",
       "6        lot   internet         rid           find  \n",
       "7      point      quote       honda     interested  \n",
       "8        use    address         buy          model  \n",
       "9        buy         hp        turn        package  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nmf_topics('nmf',20,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, NMF topics seem to be quite distinct. There does not seem to be a lot of term repetition per topic. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Assessing model quality**\n",
    "\n",
    "We have two different techniques and we would like to get a measure of how good they are. \n",
    "\n",
    "The 20newsgroups dataset has some extra test documents that we have not used in our modelling. We can somehow use these to assess our models. \n",
    "\n",
    "First we apply the same data cleaning, pre-processing and tri-gram modelling to the test documents: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testDataset=fetch_20newsgroups(shuffle=True,random_state=1,remove=('headers', 'footers', 'quotes'),subset='test')\n",
    "\n",
    "testDataset.data = [d.replace('\\n', ' ') for d in testDataset.data]\n",
    "testDataset.data = [d.replace('\\t', ' ') for d in testDataset.data]\n",
    "testDataset.data = [d.replace(\"'\",\"\") for d in testDataset.data]\n",
    "testDataset.data = [d.lower() for d in testDataset.data]\n",
    "\n",
    "testDataset.data=[doc for doc in testDataset.data if doc.find('ax>ax>') == -1]\n",
    "testDataset.data=[doc for doc in testDataset.data if doc.find('=_') == -1]\n",
    "\n",
    "test_documents=[]\n",
    "for doc in testDataset.data:\n",
    "    test_documents.append(\" \".join(\"\".join([ch for ch in doc if ch not in myPunct]).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_documents = open(\"test_documents_stripped.pickle\", \"wb\")\n",
    "pickle.dump(test_documents, save_documents)\n",
    "save_documents.close()\n",
    "\n",
    "open_file = open(\"test_documents_stripped.pickle\", \"rb\")\n",
    "test_documents = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to assess the quality of the documents by using cosine similarity.\n",
    "\n",
    "We split each test document in two halves and we apply the LDA/NMF model to each of the halves. \n",
    "\n",
    "If the model is good then the topics arising from halves of the same document should be the same most of the time. Similarly, topics arising from halves from different documents should be different in general. \n",
    "\n",
    "We can assess how similar or different the topics are by computing the cosine similarity of the resulting vectors.\n",
    "\n",
    "Similarities closer to 1 mean that the vectors have the same direction. Similarities closer to 0 mean that the vectors differ in direction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cosine_sim(a, b):\n",
    "    if len(a) != len(b):\n",
    "        raise(ValueError, \"a and b must be same length\")\n",
    "    numerator = 0\n",
    "    denoma = 0\n",
    "    denomb = 0\n",
    "    for i in range(len(a)):       \n",
    "        ai = a[i]             \n",
    "        bi = b[i]\n",
    "        numerator += ai*bi    \n",
    "        denoma += ai*ai       \n",
    "        denomb += bi*bi\n",
    "    result = numerator / (sqrt(denoma)*sqrt(denomb))\n",
    "    return result\n",
    "\n",
    "def lda_model(tokenized_docs,keep_num,alpha_val,n_topics=20):\n",
    "    trigram_dict=Dictionary(tokenized_docs)\n",
    "    trigram_dict.filter_extremes(keep_n=keep_num)\n",
    "    trigram_dict.compactify()\n",
    "    print(\"Number of features in model: {}\".format(len(trigram_dict)))\n",
    "    \n",
    "    trigram_bow_corp = [trigram_dict.doc2bow(doc) for doc in tokenized_docs]\n",
    "\n",
    "    ldamod=LdaModel(trigram_bow_corp,num_topics=n_topics,id2word=trigram_dict,alpha=alpha_val)\n",
    "    \n",
    "    return (ldamod,trigram_dict)\n",
    "\n",
    "def nmf_model(tokenized_docs,keep_num,n_topics=20):\n",
    "    tokenized_docs_str=[str(text) for text in tokenized_docs]\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=keep_num)\n",
    "    tfidf = tfidf_vectorizer.fit_transform(tokenized_docs_str)\n",
    "\n",
    "    nmf = NMF(n_components=20,init='nndsvd').fit(tfidf)\n",
    "    return(nmf,tfidf_vectorizer)\n",
    "\n",
    "def intra_inter(model_type,model_name,dict_or_vect,test_docs, num_pairs=10000):\n",
    "    if model_type == 'lda':\n",
    "        part1 = eval(\"{}[[{}.doc2bow(tokens.split()[:round(len(tokens.split())/2)]) for tokens in test_docs]]\".format(model_name,dict_or_vect))\n",
    "        part2 = eval(\"{}[[{}.doc2bow(tokens.split()[round(len(tokens.split())/2):]) for tokens in test_docs]]\".format(model_name,dict_or_vect))\n",
    "        \n",
    "        intra_mean = np.mean([cossim(p1, p2) for p1, p2 in zip(part1, part2)])\n",
    "        print(\"average cosine similarity between corresponding parts (higher is better): {}\".format(intra_mean))\n",
    "\n",
    "        random_pairs = np.random.randint(0, len(test_docs), size=(num_pairs, 2))\n",
    "        inter_mean=np.mean([cossim(part1[i[0]], part2[i[1]]) for i in random_pairs])\n",
    "        print(\"average cosine similarity between {} random parts (lower is better): {}\".format(num_pairs,inter_mean))    \n",
    "        \n",
    "    elif model_type == 'nmf':\n",
    "        part1=eval(\"[{}.transform({}.transform(str(text.split()[:round(len(text.split())/2)]) for text in test_docs))]\".format(model_name,dict_or_vect))\n",
    "        part2=eval(\"[{}.transform({}.transform(str(text.split()[round(len(text.split())/2):]) for text in test_docs))]\".format(model_name,dict_or_vect))\n",
    "        \n",
    "        cos = [cosine_sim(p1, p2) for p1, p2 in zip(part1[0], part2[0])]\n",
    "        intra_mean = np.mean([0 if isnan(c) else c for c in cos])\n",
    "        print(\"average cosine similarity between corresponding parts (higher is better): {}\".format(intra_mean))\n",
    "\n",
    "        random_pairs = np.random.randint(0, len(test_docs), size=(num_pairs, 2))\n",
    "        cos =[cosine_sim(part1[0][i[0]],part2[0][i[1]]) for i in random_pairs]\n",
    "        inter_mean=np.mean([0 if isnan(c) else c for c in cos])\n",
    "        print(\"average cosine similarity between {} random parts (lower is better): {}\".format(num_pairs,inter_mean))    \n",
    "        \n",
    "    else:\n",
    "        print('Error: only lda or nmf models are supported')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initial exploration of the results I was getting quite low 'intra' cosine similarities. I attribute this to the fact the that for shorter documents the two halves might be inherently more different. In order to be fair to the model I only keep documents to test that have more than 150 words. \n",
    "\n",
    "I will use 1000 such documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venciso\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py36\\lib\\site-packages\\gensim\\models\\phrases.py:316: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "test_doc_text=[text for text in test_documents if len(text.split())>150]\n",
    "test_doc_text=test_doc_text[:1000]\n",
    "test_doc_trans=transform_documents(test_doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average cosine similarity between corresponding parts (higher is better): 0.6923462505094791\n",
      "average cosine similarity between 1000 random parts (lower is better): 0.18954029516243434\n"
     ]
    }
   ],
   "source": [
    "intra_inter('lda','lda','trigram_dictionary',test_doc_trans,num_pairs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average cosine similarity between corresponding parts (higher is better): 0.9789740115559439\n",
      "average cosine similarity between 1000 random parts (lower is better): 0.8273055423856238\n"
     ]
    }
   ],
   "source": [
    "intra_inter('lda','lda_a','trigram_dictionary',test_doc_trans,num_pairs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venciso\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel\\__main__.py:13: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average cosine similarity between corresponding parts (higher is better): 0.6468048359264356\n",
      "average cosine similarity between 1000 random parts (lower is better): 0.24065869789743066\n"
     ]
    }
   ],
   "source": [
    "intra_inter('nmf','nmf','tfidf_vectorizer',test_doc_trans,num_pairs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the initial models it seems that LDA slightly outperforms NMF. \n",
    "\n",
    "The 'lda' model with default paramters seems to have a good balance of inter and intra cosine similarity metrics. \n",
    "\n",
    "The 'lda_a' model has really good intra similarity but the inter similarity becomes really high too. This makes sense since topics are more interrelated to each other.\n",
    "\n",
    "The 'nmf' performs similarly to 'lda' but it has a lower intra similarity and a higher inter similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can play with some of the parameters of the model to see if we can arrive to a concensus model we can use to predict new docuemnts. \n",
    "\n",
    "The two main parameters I will change are the alpha parameter in LDA and the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, Number of features: 1000\n",
      "Number of features in model: 1000\n",
      "average cosine similarity between corresponding parts (higher is better): 0.5550080791214435\n",
      "average cosine similarity between 1000 random parts (lower is better): 0.14612617207136527\n",
      "\n",
      "Alpha: 0.01, Number of features: 2500\n",
      "Number of features in model: 2500\n",
      "average cosine similarity between corresponding parts (higher is better): 0.6435816465555664\n",
      "average cosine similarity between 1000 random parts (lower is better): 0.15488015936019536\n",
      "\n",
      "Alpha: 0.01, Number of features: 5000\n",
      "Number of features in model: 5000\n",
      "average cosine similarity between corresponding parts (higher is better): 0.6740827657376589\n",
      "average cosine similarity between 1000 random parts (lower is better): 0.17079694628881598\n",
      "\n",
      "Alpha: 0.01, Number of features: 10000\n",
      "Number of features in model: 10000\n",
      "average cosine similarity between corresponding parts (higher is better): 0.7070973265973708\n",
      "average cosine similarity between 1000 random parts (lower is better): 0.23467963508804449\n",
      "\n",
      "Alpha: 0.05, Number of features: 1000\n",
      "Number of features in model: 1000\n",
      "average cosine similarity between corresponding parts (higher is better): 0.5712517120536259\n",
      "average cosine similarity between 1000 random parts (lower is better): 0.15007357932376694\n",
      "\n",
      "Alpha: 0.05, Number of features: 2500\n",
      "Number of features in model: 2500\n",
      "average cosine similarity between corresponding parts (higher is better): 0.6210734841248702\n",
      "average cosine similarity between 1000 random parts (lower is better): 0.1679358025984385\n",
      "\n",
      "Alpha: 0.05, Number of features: 5000\n",
      "Number of features in model: 5000\n",
      "average cosine similarity between corresponding parts (higher is better): 0.6732224360038679\n",
      "average cosine similarity between 1000 random parts (lower is better): 0.17614236393467714\n",
      "\n",
      "Alpha: 0.05, Number of features: 10000\n",
      "Number of features in model: 10000\n",
      "average cosine similarity between corresponding parts (higher is better): 0.7165485079214564\n",
      "average cosine similarity between 1000 random parts (lower is better): 0.21812316515587193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a in [1/100,1/20]:\n",
    "    for k in [1000,2500,5000,10000]:\n",
    "        print(\"Alpha: {}, Number of features: {}\".format(a,k))\n",
    "        model=lda_model(trigram_docs,keep_num=k,n_topics=20,alpha_val=a)\n",
    "        intra_inter(model_type='lda',model_name='model[0]',dict_or_vect='model[1]',test_docs=test_doc_trans,num_pairs=1000)      \n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in [1000,2500,5000,10000]:\n",
    "    print(\"Number of features: {}\".format(k))\n",
    "    model=nmf_model(trigram_docs,keep_num=k,n_topics=20)\n",
    "    intra_inter(model_type='nmf',model_name='model[0]',dict_or_vect='model[1]',test_docs=test_doc_trans,num_pairs=1000)      \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An LDA model with alpha= 1/100 and number of features = 5000 has a good balance of intra and inter cosine similarity metrics. \n",
    "\n",
    "Let's train a model with these parameters and keep it for prediction purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in model: 5000\n"
     ]
    }
   ],
   "source": [
    "ldaModel = lda_model(trigram_docs,keep_num=5000,n_topics=20,alpha_val=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic # 01</th>\n",
       "      <th>Topic # 02</th>\n",
       "      <th>Topic # 03</th>\n",
       "      <th>Topic # 04</th>\n",
       "      <th>Topic # 05</th>\n",
       "      <th>Topic # 06</th>\n",
       "      <th>Topic # 07</th>\n",
       "      <th>Topic # 08</th>\n",
       "      <th>Topic # 09</th>\n",
       "      <th>Topic # 10</th>\n",
       "      <th>Topic # 11</th>\n",
       "      <th>Topic # 12</th>\n",
       "      <th>Topic # 13</th>\n",
       "      <th>Topic # 14</th>\n",
       "      <th>Topic # 15</th>\n",
       "      <th>Topic # 16</th>\n",
       "      <th>Topic # 17</th>\n",
       "      <th>Topic # 18</th>\n",
       "      <th>Topic # 19</th>\n",
       "      <th>Topic # 20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>think</td>\n",
       "      <td>people</td>\n",
       "      <td>report</td>\n",
       "      <td>god</td>\n",
       "      <td>game</td>\n",
       "      <td>use</td>\n",
       "      <td>key</td>\n",
       "      <td>gun</td>\n",
       "      <td>know</td>\n",
       "      <td>drive</td>\n",
       "      <td>armenian</td>\n",
       "      <td>people</td>\n",
       "      <td>good</td>\n",
       "      <td>people</td>\n",
       "      <td>bike</td>\n",
       "      <td>program</td>\n",
       "      <td>know</td>\n",
       "      <td>program</td>\n",
       "      <td>window</td>\n",
       "      <td>think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>like</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>christian</td>\n",
       "      <td>team</td>\n",
       "      <td>file</td>\n",
       "      <td>message</td>\n",
       "      <td>file</td>\n",
       "      <td>people</td>\n",
       "      <td>know</td>\n",
       "      <td>turkey</td>\n",
       "      <td>government</td>\n",
       "      <td>car</td>\n",
       "      <td>state</td>\n",
       "      <td>israel</td>\n",
       "      <td>use</td>\n",
       "      <td>come</td>\n",
       "      <td>satellite</td>\n",
       "      <td>file</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>disease</td>\n",
       "      <td>time</td>\n",
       "      <td>book</td>\n",
       "      <td>win</td>\n",
       "      <td>work</td>\n",
       "      <td>system</td>\n",
       "      <td>church</td>\n",
       "      <td>use</td>\n",
       "      <td>system</td>\n",
       "      <td>russian</td>\n",
       "      <td>right</td>\n",
       "      <td>work</td>\n",
       "      <td>fbi</td>\n",
       "      <td>car</td>\n",
       "      <td>line</td>\n",
       "      <td>people</td>\n",
       "      <td>include</td>\n",
       "      <td>use</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>year</td>\n",
       "      <td>word</td>\n",
       "      <td>year</td>\n",
       "      <td>greek</td>\n",
       "      <td>play</td>\n",
       "      <td>system</td>\n",
       "      <td>de</td>\n",
       "      <td>people</td>\n",
       "      <td>key</td>\n",
       "      <td>problem</td>\n",
       "      <td>turk</td>\n",
       "      <td>law</td>\n",
       "      <td>use</td>\n",
       "      <td>right</td>\n",
       "      <td>like</td>\n",
       "      <td>run</td>\n",
       "      <td>think</td>\n",
       "      <td>space</td>\n",
       "      <td>display</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>know</td>\n",
       "      <td>claim</td>\n",
       "      <td>age</td>\n",
       "      <td>bible</td>\n",
       "      <td>player</td>\n",
       "      <td>software</td>\n",
       "      <td>use</td>\n",
       "      <td>find</td>\n",
       "      <td>way</td>\n",
       "      <td>like</td>\n",
       "      <td>german</td>\n",
       "      <td>gun</td>\n",
       "      <td>like</td>\n",
       "      <td>want</td>\n",
       "      <td>think</td>\n",
       "      <td>problem</td>\n",
       "      <td>tell</td>\n",
       "      <td>nasa</td>\n",
       "      <td>widget</td>\n",
       "      <td>thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "      <td>increase</td>\n",
       "      <td>belief</td>\n",
       "      <td>year</td>\n",
       "      <td>include</td>\n",
       "      <td>information</td>\n",
       "      <td>study</td>\n",
       "      <td>good</td>\n",
       "      <td>apple</td>\n",
       "      <td>jew</td>\n",
       "      <td>country</td>\n",
       "      <td>think</td>\n",
       "      <td>government</td>\n",
       "      <td>arab</td>\n",
       "      <td>window</td>\n",
       "      <td>god</td>\n",
       "      <td>information</td>\n",
       "      <td>application</td>\n",
       "      <td>believe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>come</td>\n",
       "      <td>patient</td>\n",
       "      <td>know</td>\n",
       "      <td>science</td>\n",
       "      <td>10</td>\n",
       "      <td>run</td>\n",
       "      <td>list</td>\n",
       "      <td>point</td>\n",
       "      <td>like</td>\n",
       "      <td>computer</td>\n",
       "      <td>patent</td>\n",
       "      <td>state</td>\n",
       "      <td>power</td>\n",
       "      <td>true</td>\n",
       "      <td>good</td>\n",
       "      <td>error</td>\n",
       "      <td>like</td>\n",
       "      <td>mission</td>\n",
       "      <td>server</td>\n",
       "      <td>point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>day</td>\n",
       "      <td>god</td>\n",
       "      <td>number</td>\n",
       "      <td>good</td>\n",
       "      <td>season</td>\n",
       "      <td>available</td>\n",
       "      <td>rsa</td>\n",
       "      <td>area</td>\n",
       "      <td>time</td>\n",
       "      <td>use</td>\n",
       "      <td>turkish</td>\n",
       "      <td>think</td>\n",
       "      <td>time</td>\n",
       "      <td>israel</td>\n",
       "      <td>time</td>\n",
       "      <td>file</td>\n",
       "      <td>jesus</td>\n",
       "      <td>1993</td>\n",
       "      <td>support</td>\n",
       "      <td>way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>people</td>\n",
       "      <td>world</td>\n",
       "      <td>1992</td>\n",
       "      <td>religion</td>\n",
       "      <td>12</td>\n",
       "      <td>version</td>\n",
       "      <td>work</td>\n",
       "      <td>problem</td>\n",
       "      <td>think</td>\n",
       "      <td>work</td>\n",
       "      <td>jewish</td>\n",
       "      <td>armenian</td>\n",
       "      <td>new</td>\n",
       "      <td>mean</td>\n",
       "      <td>look</td>\n",
       "      <td></td>\n",
       "      <td>die</td>\n",
       "      <td>project</td>\n",
       "      <td>datum</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>thing</td>\n",
       "      <td>think</td>\n",
       "      <td>stat</td>\n",
       "      <td>vs</td>\n",
       "      <td>good</td>\n",
       "      <td>like</td>\n",
       "      <td>security</td>\n",
       "      <td>way</td>\n",
       "      <td>want</td>\n",
       "      <td>font</td>\n",
       "      <td>p.</td>\n",
       "      <td>try</td>\n",
       "      <td>problem</td>\n",
       "      <td>way</td>\n",
       "      <td>israeli</td>\n",
       "      <td>write</td>\n",
       "      <td>want</td>\n",
       "      <td>research</td>\n",
       "      <td>include</td>\n",
       "      <td>reason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>start</td>\n",
       "      <td>fact</td>\n",
       "      <td>low</td>\n",
       "      <td>believe</td>\n",
       "      <td>11</td>\n",
       "      <td>look</td>\n",
       "      <td>include</td>\n",
       "      <td>use</td>\n",
       "      <td>pain</td>\n",
       "      <td>printer</td>\n",
       "      <td>book</td>\n",
       "      <td>time</td>\n",
       "      <td>know</td>\n",
       "      <td>like</td>\n",
       "      <td>right</td>\n",
       "      <td>change</td>\n",
       "      <td>time</td>\n",
       "      <td>contact</td>\n",
       "      <td>available</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>look</td>\n",
       "      <td>believe</td>\n",
       "      <td>use</td>\n",
       "      <td>find</td>\n",
       "      <td>14</td>\n",
       "      <td>card</td>\n",
       "      <td>pgp</td>\n",
       "      <td>consider</td>\n",
       "      <td>tell</td>\n",
       "      <td>good</td>\n",
       "      <td>like</td>\n",
       "      <td>want</td>\n",
       "      <td>look</td>\n",
       "      <td>question</td>\n",
       "      <td>palestinian</td>\n",
       "      <td>try</td>\n",
       "      <td>christian</td>\n",
       "      <td>datum</td>\n",
       "      <td>subject</td>\n",
       "      <td>mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>run</td>\n",
       "      <td>child</td>\n",
       "      <td>post</td>\n",
       "      <td>time</td>\n",
       "      <td>13</td>\n",
       "      <td>good</td>\n",
       "      <td>know</td>\n",
       "      <td>state</td>\n",
       "      <td>system</td>\n",
       "      <td>monitor</td>\n",
       "      <td>europe</td>\n",
       "      <td>know</td>\n",
       "      <td>year</td>\n",
       "      <td>israeli</td>\n",
       "      <td>come</td>\n",
       "      <td>find</td>\n",
       "      <td>work</td>\n",
       "      <td>development</td>\n",
       "      <td>run</td>\n",
       "      <td>argument</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lot</td>\n",
       "      <td>treatment</td>\n",
       "      <td>available</td>\n",
       "      <td>faith</td>\n",
       "      <td>15</td>\n",
       "      <td>program</td>\n",
       "      <td>encryption</td>\n",
       "      <td>year</td>\n",
       "      <td>car</td>\n",
       "      <td>thank</td>\n",
       "      <td>washington</td>\n",
       "      <td>american</td>\n",
       "      <td>engine</td>\n",
       "      <td>think</td>\n",
       "      <td>road</td>\n",
       "      <td>set</td>\n",
       "      <td>find</td>\n",
       "      <td>system</td>\n",
       "      <td>problem</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>way</td>\n",
       "      <td>thing</td>\n",
       "      <td>cause</td>\n",
       "      <td>know</td>\n",
       "      <td>16</td>\n",
       "      <td>list</td>\n",
       "      <td>mail</td>\n",
       "      <td>pope</td>\n",
       "      <td>msg</td>\n",
       "      <td>buy</td>\n",
       "      <td>new</td>\n",
       "      <td>criminal</td>\n",
       "      <td>thing</td>\n",
       "      <td>post</td>\n",
       "      <td>kill</td>\n",
       "      <td>entry</td>\n",
       "      <td>thing</td>\n",
       "      <td>technology</td>\n",
       "      <td>mac</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>great</td>\n",
       "      <td>jesus</td>\n",
       "      <td>high</td>\n",
       "      <td>think</td>\n",
       "      <td>25</td>\n",
       "      <td>machine</td>\n",
       "      <td>number</td>\n",
       "      <td>couple</td>\n",
       "      <td>chip</td>\n",
       "      <td>ms</td>\n",
       "      <td>people</td>\n",
       "      <td>like</td>\n",
       "      <td>want</td>\n",
       "      <td>case</td>\n",
       "      <td>guy</td>\n",
       "      <td>display</td>\n",
       "      <td>live</td>\n",
       "      <td>work</td>\n",
       "      <td>sun</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>jesus</td>\n",
       "      <td>case</td>\n",
       "      <td>test</td>\n",
       "      <td>mean</td>\n",
       "      <td>20</td>\n",
       "      <td>email</td>\n",
       "      <td>time</td>\n",
       "      <td>new</td>\n",
       "      <td>government</td>\n",
       "      <td>disk</td>\n",
       "      <td>1982</td>\n",
       "      <td>weapon</td>\n",
       "      <td>way</td>\n",
       "      <td>clipper</td>\n",
       "      <td>helmet</td>\n",
       "      <td>follow</td>\n",
       "      <td>man</td>\n",
       "      <td>new</td>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>game</td>\n",
       "      <td>know</td>\n",
       "      <td>like</td>\n",
       "      <td>man</td>\n",
       "      <td>score</td>\n",
       "      <td>set</td>\n",
       "      <td>send</td>\n",
       "      <td>plane</td>\n",
       "      <td>thing</td>\n",
       "      <td>ram</td>\n",
       "      <td>file</td>\n",
       "      <td>force</td>\n",
       "      <td>cost</td>\n",
       "      <td>place</td>\n",
       "      <td>know</td>\n",
       "      <td>system</td>\n",
       "      <td>hear</td>\n",
       "      <td>international</td>\n",
       "      <td>software</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>work</td>\n",
       "      <td>true</td>\n",
       "      <td>1991</td>\n",
       "      <td>people</td>\n",
       "      <td>king</td>\n",
       "      <td>color</td>\n",
       "      <td>standard</td>\n",
       "      <td>safety</td>\n",
       "      <td>work</td>\n",
       "      <td>mb</td>\n",
       "      <td>work</td>\n",
       "      <td>case</td>\n",
       "      <td>line</td>\n",
       "      <td>information</td>\n",
       "      <td>new</td>\n",
       "      <td>application</td>\n",
       "      <td>good</td>\n",
       "      <td>fund</td>\n",
       "      <td>set</td>\n",
       "      <td>try</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>want</td>\n",
       "      <td>point</td>\n",
       "      <td>da</td>\n",
       "      <td>accept</td>\n",
       "      <td>18</td>\n",
       "      <td>new</td>\n",
       "      <td>function</td>\n",
       "      <td>council</td>\n",
       "      <td>need</td>\n",
       "      <td>tape</td>\n",
       "      <td>germany</td>\n",
       "      <td>president</td>\n",
       "      <td>big</td>\n",
       "      <td>chastity_intellect_gebcadre.dsl.pitt.edu_shameful</td>\n",
       "      <td>leave</td>\n",
       "      <td>know</td>\n",
       "      <td>kill</td>\n",
       "      <td>orbit</td>\n",
       "      <td>program</td>\n",
       "      <td>consider</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic # 01 Topic # 02 Topic # 03 Topic # 04 Topic # 05 Topic # 06  \\\n",
       "0       think     people     report        god       game        use   \n",
       "1        like       good       good  christian       team       file   \n",
       "2        good    disease       time       book        win       work   \n",
       "3        year       word       year      greek       play     system   \n",
       "4        know      claim        age      bible     player   software   \n",
       "5        time       time   increase     belief       year    include   \n",
       "6        come    patient       know    science         10        run   \n",
       "7         day        god     number       good     season  available   \n",
       "8      people      world       1992   religion         12    version   \n",
       "9       thing      think       stat         vs       good       like   \n",
       "10      start       fact        low    believe         11       look   \n",
       "11       look    believe        use       find         14       card   \n",
       "12        run      child       post       time         13       good   \n",
       "13        lot  treatment  available      faith         15    program   \n",
       "14        way      thing      cause       know         16       list   \n",
       "15      great      jesus       high      think         25    machine   \n",
       "16      jesus       case       test       mean         20      email   \n",
       "17       game       know       like        man      score        set   \n",
       "18       work       true       1991     people       king      color   \n",
       "19       want      point         da     accept         18        new   \n",
       "\n",
       "     Topic # 07 Topic # 08  Topic # 09 Topic # 10  Topic # 11  Topic # 12  \\\n",
       "0           key        gun        know      drive    armenian      people   \n",
       "1       message       file      people       know      turkey  government   \n",
       "2        system     church         use     system     russian       right   \n",
       "3            de     people         key    problem        turk         law   \n",
       "4           use       find         way       like      german         gun   \n",
       "5   information      study        good      apple         jew     country   \n",
       "6          list      point        like   computer      patent       state   \n",
       "7           rsa       area        time        use     turkish       think   \n",
       "8          work    problem       think       work      jewish    armenian   \n",
       "9      security        way        want       font          p.         try   \n",
       "10      include        use        pain    printer        book        time   \n",
       "11          pgp   consider        tell       good        like        want   \n",
       "12         know      state      system    monitor      europe        know   \n",
       "13   encryption       year         car      thank  washington    american   \n",
       "14         mail       pope         msg        buy         new    criminal   \n",
       "15       number     couple        chip         ms      people        like   \n",
       "16         time        new  government       disk        1982      weapon   \n",
       "17         send      plane       thing        ram        file       force   \n",
       "18     standard     safety        work         mb        work        case   \n",
       "19     function    council        need       tape     germany   president   \n",
       "\n",
       "   Topic # 13                                         Topic # 14   Topic # 15  \\\n",
       "0        good                                             people         bike   \n",
       "1         car                                              state       israel   \n",
       "2        work                                                fbi          car   \n",
       "3         use                                              right         like   \n",
       "4        like                                               want        think   \n",
       "5       think                                         government         arab   \n",
       "6       power                                               true         good   \n",
       "7        time                                             israel         time   \n",
       "8         new                                               mean         look   \n",
       "9     problem                                                way      israeli   \n",
       "10       know                                               like        right   \n",
       "11       look                                           question  palestinian   \n",
       "12       year                                            israeli         come   \n",
       "13     engine                                              think         road   \n",
       "14      thing                                               post         kill   \n",
       "15       want                                               case          guy   \n",
       "16        way                                            clipper       helmet   \n",
       "17       cost                                              place         know   \n",
       "18       line                                        information          new   \n",
       "19        big  chastity_intellect_gebcadre.dsl.pitt.edu_shameful        leave   \n",
       "\n",
       "     Topic # 16 Topic # 17     Topic # 18   Topic # 19 Topic # 20  \n",
       "0       program       know        program       window      think  \n",
       "1           use       come      satellite         file     people  \n",
       "2          line     people        include          use       good  \n",
       "3           run      think          space      display       know  \n",
       "4       problem       tell           nasa       widget      thing  \n",
       "5        window        god    information  application    believe  \n",
       "6         error       like        mission       server      point  \n",
       "7          file      jesus           1993      support        way  \n",
       "8                      die        project        datum       mean  \n",
       "9         write       want       research      include     reason  \n",
       "10       change       time        contact    available       want  \n",
       "11          try  christian          datum      subject         mr  \n",
       "12         find       work    development          run   argument  \n",
       "13          set       find         system      problem      human  \n",
       "14        entry      thing     technology          mac       true  \n",
       "15      display       live           work          sun      right  \n",
       "16       follow        man            new         like       like  \n",
       "17       system       hear  international     software      agree  \n",
       "18  application       good           fund          set        try  \n",
       "19         know       kill          orbit      program   consider  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lda_topics('ldaModel[0]',20,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the topics and try to assign names to them. Going through the 20 topics is interesting, we can see some of them are not immediately straightforward to categorise and others can be interpreted as a mix of two different topics but in general one can identify a thread through the topic words. \n",
    "Here we can also see that some funny terms are still showing up even after we made efforts to clean the documents. The claening process can therefore probably be further optimised. \n",
    "One other note is that even though the number of topics is supposed to be 20 there are a few instances where topics can be the repeated across groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_names={\n",
    "    0: 'miscellaneous',\n",
    "    1: 'medicine',\n",
    "    2: 'miscellaneous 1',\n",
    "    3: 'religion',\n",
    "    4: 'sports',\n",
    "    5: 'software',\n",
    "    6: 'encryption',\n",
    "    7: 'guns',\n",
    "    8: 'politics',\n",
    "    9: 'computing',\n",
    "    10: 'foreign politics', \n",
    "    11: 'politics',\n",
    "    12: 'cars',\n",
    "    13: 'politics 1',\n",
    "    14: 'middle east/cars mix',\n",
    "    15: 'computing',\n",
    "    16: 'christianity',\n",
    "    17: 'space',\n",
    "    18: 'computing 1',\n",
    "    19: 'religious/atheist discussion'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prediction of unseen documents**\n",
    "\n",
    "The dataset I chose to use actually has the news gorup labels for each document. This means that I could have predicted the labels with both LDA and NMF models and assessed which one was better based on the accuracy.\n",
    "\n",
    "I decided not to pursue this for a couple of reasons:\n",
    "* We know the 'answers' for this particular dataset but in general the labels will be unknown so it will not be possible to apply this kind of method.\n",
    "* The fact that a comment was left in a particular newsgroup doesn't necessarily mean that it is about the same topic. It will be the case in general but nobody prevent someone going into the 'atheism' group and talk about something completely different. My point being that the labels are not a perfect representation of 'topics'\n",
    "\n",
    "For curiosity's sake, below are the real 'topics'. If we examine the names we can see that indeed a few topics are interrelated/repeated. The topics that we assigned don't match exactly one to one to these topics but there is good coverage of the different themes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'alt.atheism',\n",
       " 1: 'comp.graphics',\n",
       " 2: 'comp.os.ms-windows.misc',\n",
       " 3: 'comp.sys.ibm.pc.hardware',\n",
       " 4: 'comp.sys.mac.hardware',\n",
       " 5: 'comp.windows.x',\n",
       " 6: 'misc.forsale',\n",
       " 7: 'rec.autos',\n",
       " 8: 'rec.motorcycles',\n",
       " 9: 'rec.sport.baseball',\n",
       " 10: 'rec.sport.hockey',\n",
       " 11: 'sci.crypt',\n",
       " 12: 'sci.electronics',\n",
       " 13: 'sci.med',\n",
       " 14: 'sci.space',\n",
       " 15: 'soc.religion.christian',\n",
       " 16: 'talk.politics.guns',\n",
       " 17: 'talk.politics.mideast',\n",
       " 18: 'talk.politics.misc',\n",
       " 19: 'talk.religion.misc'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_topic_names={}\n",
    "for int,cat in enumerate(testDataset.target_names):\n",
    "    real_topic_names[int]=cat\n",
    "real_topic_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply our LDA model to a particular unseen document and get a probability of the document having been generated by a number of topics. \n",
    "\n",
    "In order do this we create another function that processes the document, applies the LDA model and spits out a prediction based on the topics that have the highest probability og having generated that document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def takeSecond(elem):\n",
    "    return elem[1]\n",
    "\n",
    "def lda_description(text, min_topic_freq=0.05):\n",
    "    parsed_doc = nlp(text)\n",
    "    \n",
    "    unigram_doc=[]\n",
    "\n",
    "    for token in parsed_doc:\n",
    "        if not punct_space(token):\n",
    "            if token.lemma_ == '-PRON-':\n",
    "                unigram_doc.append(token.orth_)\n",
    "            elif token.lemma_ not in spacy.en.STOP_WORDS:\n",
    "                unigram_doc.append(token.lemma_)\n",
    "\n",
    "    bigram_doc = bigram_model[unigram_doc]\n",
    "    trigram_doc = trigram_model[bigram_doc]\n",
    "    trigram_doc = [term for term in trigram_doc]\n",
    "    \n",
    "    #trigram_doc = ' '.join(trigram_doc)\n",
    "    trigram_doc = [term for term in trigram_doc if len(term)>1]\n",
    "\n",
    "    trigram_transformed_docs.append(trigram_doc)\n",
    "\n",
    "    # create a bag-of-words representation\n",
    "    doc_bow = ldaModel[1].doc2bow(trigram_doc)\n",
    "    \n",
    "    # create an LDA representation\n",
    "    doc_lda = ldaModel[0][doc_bow]\n",
    "    \n",
    "    # sort with the most highly related topics first\n",
    "    doc_lda = sorted(doc_lda, key=takeSecond, reverse=True)\n",
    "    \n",
    "    for topic_number, freq in doc_lda:\n",
    "        if freq < min_topic_freq:\n",
    "            break\n",
    "            \n",
    "        # print the most highly related topic names and frequencies\n",
    "        print('{:35} {}'.format(topic_names[topic_number],\n",
    "                                round(freq, 3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some random documents and se what happens. Here again I will take documents with more than 150 words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_docs=[text for text in test_documents if len(text.split())>150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i once heard an arguement from a xtian friend similar to this. christianity is a higher logic. athiest like u will not be able to understand it. your atheist logic is very low. only thru faith can we understand the higher logic in god. so i asked him, so what is this higher logic his answer, i dont know. this, the posting above highlights one of the worst things about xtainity. it is abundantly clear to both atheists xtains that their believe is both illogical irrational. their tactics, therefore to disregard logic rationality altogether. silly excuses such as the ones above and those such as, how can u trust science, science was invented by man, only goes to further show the weakness of their religion. in my country where xtainity was and still is rapidly growing, xtains never try to convert people by appealing to their brains or senses. they know it would be a fruitless act, given the irrational nature of their faith. they would wait until a person is in distress, then they would comfort himher and addict them to their emotional opium. never in my life had i met a person who converted to xtainity coz its reasonable. rationality has no place in xtainity see xtian arguement against reason above. the unenlightened one tan chade meng the wise man tells his wife that he understands her. singapore cmtaniss.nus.sg the fool tries to prove it.\n",
      "\n",
      "Topics from model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venciso\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py36\\lib\\site-packages\\gensim\\models\\phrases.py:316: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "religious/atheist discussion        0.437\n",
      "christianity                        0.244\n",
      "religion                            0.211\n",
      "miscellaneous                       0.106\n",
      "__________________________________________________\n",
      "i have a mystery part labeled nec ac100. its from the low voltage supply of an nec multisync i monitor. its a three lead part in a square package like a volate regulator or power transistor. the board is labeled cr691 where the part goes. possibly an scr the pin labeled g on the board goes to a zener diode reference voltage the pin labeled t1 goes to the negative lead of a capacitor in the power supply, and the pin labeled t2 goes to the negative side of the bridge rectifier in the supply. if anyone can tell me what this is, or better yet, where i can buy one just like it, please email me at ck3iandrew.cmu.edu. ive called necs monitor repair number and not only do they not know what the part is, but they dont think that they can find one to sell to me... it makes no sense to me...\n",
      "\n",
      "Topics from model:\n",
      "computing                           0.496\n",
      "cars                                0.432\n",
      "religion                            0.068\n",
      "__________________________________________________\n",
      "in 1993apr24.214843.10940midway.uchicago.edu eeb1quads.uchicago.edu if the only people proposing a moment of silence are doing so as a sham to sneak in prayers, then it must be opposed. what the hell have prayers to do with public schooling i ask this question as a devout christian. their kids can bloodywell pray any goddamned time they want to. and nothing, on heaven or earth, in government or the principals office, can prevent or in any other way deal with their doing so. especially if the prayer is silent as bursting out into the shema yisrael or some other prayer might be construed as disruptive if audible no one ever prevented me from praying in public school they hardly even prevented me from masturbating in study hall. i should have thought better of someone posting from a uchicago address. how can you manage to say such nonsense without shame muslim students might have a complaint, if they are prevented from setting out their rugs and doing the proper ablutions before prayer at the times specified in the quran. jews would probably like the opportunity to daven with tefillim and whatever else they require, at their appropriate times. i do not see them complaining though muslims and jews have a case that no christian i have ever heard has been able to make. the christian insistence on a public, universal, enforced moment of prayerhhhhhhsilence is nothing but the inquisition naturalized into the american context. it is offensive to the gospel of christ.\n",
      "\n",
      "Topics from model:\n",
      "christianity                        0.476\n",
      "politics                            0.227\n",
      "religious/atheist discussion        0.147\n",
      "miscellaneous                       0.092\n",
      "space                               0.057\n",
      "__________________________________________________\n",
      "while im sure sagan considers it sacrilegious, that wouldnt be because of his doubtfull credibility as an astronomer. modern, groundbased, visible light astronomy what these proposed orbiting billboards would upset is already a dying field the opacity and distortions caused by the atmosphere itself have driven most of the field to use radio, far infrared or spacebased telescopes. hardly. the keck telescope in hawaii has taken its first pictures theyre nearly as good as hubble for a tiny fraction of the cost. in any case, a bright point of light passing through the field doesnt ruin observations. if that were the case, the thousands of existing satellites would have already done so satelliets might not seem so bright to the eyes, but as far as astronomy is concerned, they are extremely bright. i believe that this orbiting space junk will be far brighter still more like the full moon. the moon upsets deepsky observation all over the sky and not just looking at it because of scattered light. this is a known problem, but of course two weeks out of every four are ok. what happens when this billboard circles every 90 minutes what would be a good time then frank crary cu boulder\n",
      "\n",
      "Topics from model:\n",
      "space                               0.322\n",
      "miscellaneous                       0.32\n",
      "medicine                            0.161\n",
      "christianity                        0.122\n",
      "cars                                0.055\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "randInds=[459,672,1390,2000]\n",
    "for i in randInds:\n",
    "    doc=test_docs[i]\n",
    "    #topic_id=test_docs[i][1]\n",
    "    #print(\"Document from newsgroup: {} \\n\".format(real_topic_names[topic_id]))\n",
    "    print(doc)\n",
    "    print(\"\")\n",
    "    print(\"Topics from model:\")\n",
    "    (lda_description(doc))\n",
    "    print(\"__________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong about what i think they are correct in thinking that a wellplaced bomb or six would get headlines, but i think they are wrong if they think that you can set off bombs and still be a buddhist. maybe what we are seeing here is that chinese cultural genocide against the tibetans has worked well enough that some tibetans are now no longer buddhist and are instead willing to behave like the chinese occupiers. every action is its own reward. on the other hand, people who are aware of the occupation are mostly full of admiration for the peaceful way that tibetans have put up with it. and what does it cost us to admire them zip. yes they are, and whether this serves them well or not depends on whether they want buddhist principles or political independence. and without political independence can they preserve their cultural and religious traditions the chinese would certainly refer to them as terrorists, just as the hitler regime used to refer to european resistance movements as terrorists. better off in what way as proponents of pacifism or as proponents of political autonomy and better off in what timescale the soviet empire practised cultural genocide against something like a hundred small minorities, some of which resisted violently, and some of which did not, but in the end it was the soviet empire that collapsed and at least some of the minorities survived. now some of the minorities are fighting one another. is that because they have to, or because violent resistance to an oppressive empire legitimized violence\n",
      "\n",
      "Topics from model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venciso\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py36\\lib\\site-packages\\gensim\\models\\phrases.py:316: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politics                            0.631\n",
      "foreign politics                    0.142\n",
      "medicine                            0.119\n",
      "politics                            0.106\n",
      "__________________________________________________\n",
      "if i get a chance i will ask them this weekend. the words i have underlined are at the heart of the problem. a quick look doesnt do justice to the depth of the book of jeremiah. having studied the jeremiahezekial period solidly for over a year at one stage of my life, i have to say that there is a great deal of underlying theological meaning in the judgement prophesies. let me make one point. the clash between jeremiah and the false prophets was primarily in the theological realm. the false prophets understood their relatioship to god to be based on the covenant that the lord made with david. it is possible to trace within the pages of the old testament who this covenant, which was initially conditional on the continued obedience of davids descendants, came to be viewed as an unconditional promise on the part of the lord to keep a descendant of davids upon the throne and to never allow jerusalem to subjegated by any foreign power. jeremiah was not a judahite prophet. he was from anathoth, across the border in what had formerly been israelite territory. when he came to prophesy, he came from the theological background of the covenant the lord had made with israel through moses. the northern kingdom had rejected the davidic covenant after the death of solomon. his theology clashed with the theology of the local prophets. it was out of a very deep understanding of the mosaic covenant and an actute awareness of international events that jeremiah spoke his prophesies. the judgement prophesies were deeply loaded with theological meaning. in my opinion, both the portland earthquake prophesy and the david wilkerson new york will burn prophesy are froth and bubble compared to the majestic theological depths of the jeremiah prophesies. bill rea o o wuw\n",
      "\n",
      "Topics from model:\n",
      "christianity                        0.396\n",
      "medicine                            0.289\n",
      "religion                            0.209\n",
      "miscellaneous                       0.104\n",
      "__________________________________________________\n",
      "ive found mine 93 probe gt to do quite well. window problem deleted, artical has been trimmed ive not had any of the air or leakage problems that have been reported but do get the squeal that bill describes. i live in seattle so the wet weather may be a factor. if i recall correctly i got two keys. this is true. im wondering if this may be a safety concern. ie, if people pound on the place where the airbag lives... no opinion. the 5 speed is much more fun. we opted for the automatic for a number of reasons but its still fun, and in some ways more practical. ditto. i too would suspect that this may be true. yes ditto. agree. check it out. i dont mind it but would say that if it was much stiffer it might be a problem. how about the 93 r1 rx7 for suspension true. ive had this problem and read about it. or at least i assume the one i had was the one i read about . in any case what happened was the weld between the muffler and the pipe feeding it ok, so im not a mechanic broke. in my case the dealer welded it, ordered replacement parts and put them on when they got them. i suspect this is some sort of 1 design flaw, or 2 production flaw. in any case i have an earlier model and would expect it to be worked out on newer ones. in any case it is a warrantee repair. or they get the keys back i second this. there seems to be some things that slipped through but the car seems very sound. while not perfection what is you get an awful lot for your money. btw, bill has a probe mailing list. you might want to subscribe to it if you are interested in more detail. try requestfordprobeworld.std.com did i get that right never can remember if the request goes on the front or the back\n",
      "\n",
      "Topics from model:\n",
      "cars                                0.312\n",
      "politics                            0.271\n",
      "software                            0.121\n",
      "miscellaneous 1                     0.108\n",
      "middle east/cars mix                0.094\n",
      "religious/atheist discussion        0.093\n",
      "__________________________________________________\n",
      "i dont think joe was saying any such thing. however, your question on asking jesus to come into your heart seems to imply that infants are not allowed to have christ in theirs. why must baptism always be viewed by some people as a sort of prodigal son type of thing i.e. a sudden change of heart, going from not accepting christ to suddenly accepting christ why cant people start out with christ from shortly after birth, and build their relationship from there after all, does a man suddenly meet a woman, and then marry her that same day from my experiences, ive learned that all relationships must be built, including ones relationship with god. also joe is speaking from the standpoint that baptism is not just a ritual, but that through it god bestows sacramental grace upon the recipient. certainly for those with the mental faculties to know christ it is necessary to believe in him. however, the sacrament itself bestows grace on the recipient, and makes a permanent mark of adoption into gods family on the soul.\n",
      "\n",
      "Topics from model:\n",
      "christianity                        0.472\n",
      "miscellaneous                       0.398\n",
      "religious/atheist discussion        0.127\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "randInds=[119,67,1860,2041]\n",
    "for i in randInds:\n",
    "    doc=test_docs[i]\n",
    "    #topic_id=test_docs[i][1]\n",
    "    #print(\"Document from newsgroup: {} \\n\".format(real_topic_names[topic_id]))\n",
    "    print(doc)\n",
    "    print(\"\")\n",
    "    print(\"Topics from model:\")\n",
    "    (lda_description(doc))\n",
    "    print(\"__________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general topic prediction is performing well. In most cases the first or second topics seem to describe the theme of the document. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary and final notes**\n",
    "\n",
    "In this notebook we have gone through all the necessary steps to create a model that infers topics from a given document.\n",
    "\n",
    "One final note is that both the spacy and gensim modules support streaming and parallelisation which will be useful/necessary if the number of documents to analyse grows significantly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below just saves the necesary bits to make a class to use outside of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldaModel[0].save('lda_final_model')\n",
    "\n",
    "save_documents = open(\"bigram_model.pickle\", \"wb\")\n",
    "pickle.dump(bigram_model, save_documents)\n",
    "save_documents.close()\n",
    "\n",
    "save_documents = open(\"trigram_model.pickle\", \"wb\")\n",
    "pickle.dump(trigram_model, save_documents)\n",
    "save_documents.close()\n",
    "\n",
    "save_documents = open(\"trigram_dictionary.pickle\", \"wb\")\n",
    "pickle.dump(trigram_dictionary, save_documents)\n",
    "save_documents.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
